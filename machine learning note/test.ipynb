{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 载入数据\n",
    "dataset = np.loadtxt('../machine learning note/watermelon_3a.csv', delimiter=',')\n",
    "X = dataset[:,1:3]\n",
    "y = dataset[:,3]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 绘制散点图\n",
    "plt.scatter(X[y==0][:,0],X[y==0][:,1],color='red',s=100,label='Good')\n",
    "plt.scatter(X[y==1][:,0],X[y==1][:,1],color='blue',s=100,label='Bad')\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('Sugar')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "        \n",
    "# Sigmoid函数\n",
    "def sigmoid(X,beta):\n",
    "    return 1.0 / (1+np.exp(-np.dot(X,beta)))\n",
    "\n",
    "# 分布率\n",
    "def likelihood_sub(X,y,beta):\n",
    "    return -y * np.dot(beta,X.T) + np.log(1 + np.exp(np.dot(beta,X.T)))\n",
    "\n",
    "# 似然函数\n",
    "def likelihood(X,y,beta):\n",
    "    num = len(y)\n",
    "    sum = 0\n",
    "    for i in range(num):\n",
    "        sum += likelihood_sub(X[i],y[i],beta)\n",
    "    return sum\n",
    "\n",
    "# 梯度下降每一次参数更新，对应公式3.30\n",
    "def gradient_step(alpha,X,y,beta):\n",
    "    prediction  = sigmoid(X,beta)\n",
    "    error = prediction - y\n",
    "    gradientStep = alpha * np.dot(X.T,error)    \n",
    "    beta -= gradientStep\n",
    "    return beta\n",
    "\n",
    "# 批量梯度下降\n",
    "def gradient_descent(X,y,beta,alpha,num_iterations):   \n",
    "    for i in range(num_iterations):\n",
    "        beta = gradient_step(alpha,X,y,beta)\n",
    "        loss = likelihood(X,y,beta)\n",
    "        # print('Iteration:',i,'Loss:',loss)\n",
    "    return beta,loss\n",
    "\n",
    "# 随机梯度下降（每次只沿着一个方向下降）\n",
    "def stochastic_gradient_descent(X, y, beta, alpha, num_epochs):\n",
    "    sample_size = X.shape[0]\n",
    "    for i in range(num_epochs):\n",
    "        X, y = shuffle(X, y)  # 打乱数据顺序\n",
    "        for j in range(sample_size):\n",
    "            beta = gradient_step(alpha, X[j], y[j], beta)\n",
    "        loss = likelihood(X, y, beta)\n",
    "    return beta, loss\n",
    "\n",
    "# 预测函数\n",
    "def predict(X,beta):\n",
    "    sample_size = X.shape[0]\n",
    "    y = np.zeros(sample_size)\n",
    "    for i in range(sample_size):\n",
    "        if sigmoid(X[i],beta) > 0.5:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    return y\n",
    "\n",
    "# 计算准确率\n",
    "def accuracy(y_true,y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "# 训练模型\n",
    "feature_size = X_train.shape[1]\n",
    "beta = np.zeros(feature_size + 1)\n",
    "alpha = 0.1\n",
    "num_iterations = 500\n",
    "X_train = np.c_[X_train,np.ones((X_train.shape[0],1))]\n",
    "X_test = np.c_[X_test,np.ones((X_test.shape[0],1))]\n",
    "beta,loss = gradient_descent(X_train,y_train,beta,alpha,num_iterations)\n",
    "print('beta:',beta)\n",
    "predictions = predict(X_test,beta)\n",
    "accuracy_score = accuracy(y_test,predictions)\n",
    "print('accuracy_score:',accuracy_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self,fit_intercept=True,method='batch',\n",
    "                 learning_rate=0.1,max_iter=1000,random_state=None):\n",
    "        \"\"\"\n",
    "        逻辑回归分类器\n",
    "        \n",
    "        参数:\n",
    "        - fit_intercept: 是否添加偏置项 (默认True)\n",
    "        - method: 优化方法 ['batch'(批量梯度下降), 'stochastic'(随机梯度下降)] (默认'batch')\n",
    "        - learning_rate: 学习率 (默认0.1)\n",
    "        - max_iter: 最大迭代次数 (默认500)\n",
    "        - random_state: 随机种子 (默认None)\n",
    "        \"\"\"\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.method = method\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.beta = None\n",
    "        self.loss_history = []\n",
    "\n",
    "    def add_intercept(self,X):\n",
    "        \"\"\"设置偏置项(X,1)\"\"\"\n",
    "        if self.fit_intercept:\n",
    "            return np.c_[X,np.ones(X.shape[0])]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "    def sigmoid(self,z):\n",
    "        \"\"\"sigmoid函数\"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "    \n",
    "    def loss(self,X,y):\n",
    "        \"\"\"计算似然损失(3.27)\"\"\"\n",
    "        z = X @ self.beta\n",
    "        loss_terms = -y * z + np.log(1 + np.exp(-z))\n",
    "        return np.sum(loss_terms)\n",
    "\n",
    "    def batch_gradient_step(self,X,y):\n",
    "        \"\"\"批量梯度下降更新参数(3.30)\"\"\" \n",
    "        p = self.sigmoid(X @ self.beta)\n",
    "        gradent = X.T @ (p - y)\n",
    "        self.beta -= self.learning_rate * gradent\n",
    "\n",
    "    def stochastic_gradient_step(self,X,y):\n",
    "        \"\"\"随机梯度下降更新参数(一次随机更新一个方向)\"\"\"\n",
    "        for i in range(X.shape[0]):\n",
    "             p = self.sigmoid(X[i] @ self.beta)\n",
    "             gradent = X[i] * (p - y[i])\n",
    "             self.beta -= self.learning_rate * gradent\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "        训练模型\n",
    "        \n",
    "        参数:\n",
    "        - X: 特征矩阵 (n_samples, n_features)\n",
    "        - y: 标签向量 (n_samples,)\n",
    "        \"\"\"\n",
    "\n",
    "        # 数据预处理(m个数据，n-1个特征)\n",
    "        X = self.add_intercept(X)\n",
    "        m,n = X.shape\n",
    "        self.beta = np.zeros(n)\n",
    "\n",
    "        # 设置随机种子\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        # 选择优化方法\n",
    "        if self.method == 'batch':\n",
    "            optimizer = self.batch_gradient_step\n",
    "        elif self.method =='stochastic':\n",
    "            optimizer = self.stochastic_gradient_step\n",
    "        else:\n",
    "            raise ValueError(\"method must be 'batch' or'stochastic'\")\n",
    "\n",
    "        # 训练模型\n",
    "        for epoch in range(self.max_iter):\n",
    "            # 随机梯度下降每次迭代后随机打乱数据\n",
    "            if self.method == 'stochastic':\n",
    "                X,y = shuffle(X,y)\n",
    "\n",
    "            # 执行一次梯度下降更新\n",
    "            optimizer(X,y)\n",
    "\n",
    "            # 记录损失\n",
    "            self.loss_history.append(self.loss(X,y))\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        \"\"\"返回预测概率\"\"\"\n",
    "        X = self.add_intercept(X)\n",
    "        return self.sigmoid(X @ self.beta)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"返回预测类别\"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba >= 0.5).astype(int)\n",
    "\n",
    "    def score(self,X,y):\n",
    "        \"\"\"计算准确率\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)\n",
    "    \n",
    "    def plot_loss_curve(self):\n",
    "        \"\"\"绘制损失变化图\"\"\"\n",
    "        plt.plot(self.loss_history)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_decision_boundary(self,X,y):\n",
    "        \"\"\"绘制决策边界\"\"\"\n",
    "        if X.shape[1] != 2:\n",
    "            raise ValueError(\"只支持二维特征可视化!\")\n",
    "        # 提取模型参数\n",
    "        w1, w2, b = self.beta[0], self.beta[1], self.beta[2]\n",
    "        \n",
    "        # 生成网格点坐标\n",
    "        x_min, x_max = X[:,0].min()-0.1, X[:,0].max()+0.1\n",
    "        y_min, y_max = X[:,1].min()-0.1, X[:,1].max()+0.1\n",
    "        xx = np.linspace(x_min, x_max, 100)\n",
    "        \n",
    "        # 计算决策边界直线方程：w1*x1 + w2*x2 + b = 0 → x2 = (-w1*x1 -b)/w2\n",
    "        decision_line = (-w1 * xx - b) / w2\n",
    "        \n",
    "        # 创建画布\n",
    "        plt.figure(figsize=(8,6))\n",
    "        \n",
    "        # 绘制原始数据点\n",
    "        plt.scatter(X[y==0][:,0], X[y==0][:,1], color='red', \n",
    "                    edgecolor='k', s=100, label='Bad')\n",
    "        plt.scatter(X[y==1][:,0], X[y==1][:,1], color='blue', \n",
    "                    edgecolor='k', s=100, label='Good')\n",
    "        \n",
    "        # 绘制决策边界\n",
    "        plt.plot(xx, decision_line, 'k--', lw=2, \n",
    "                label=f'Decision Boundary\\n{w1:.2f}x1 + {w2:.2f}x2 + {b:.2f} = 0')\n",
    "        \n",
    "        # 美化显示\n",
    "        plt.xlabel(\"Density\")\n",
    "        plt.ylabel(\"Sugar\")\n",
    "        plt.title(\"Decision Boundary\")\n",
    "        plt.legend(bbox_to_anchor=(1, 0.5), loc='center left')\n",
    "        plt.xlim(x_min, x_max)\n",
    "        plt.ylim(y_min, y_max)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 加载数据\n",
    "    dataset = np.loadtxt('../machine learning note/watermelon_3a.csv', delimiter=',')\n",
    "    X = dataset[:, 1:3]\n",
    "    y = dataset[:, 3]\n",
    "\n",
    "    # 划分数据集(0.3的测试集)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # 初始化模型(批量梯度下降)\n",
    "    model = LogisticRegression(\n",
    "        method='batch',       \n",
    "        learning_rate=0.1,\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 评估模型\n",
    "    print(\"模型参数:\", model.beta)\n",
    "    print(\"测试集准确率:\", model.score(X_test, y_test))\n",
    "\n",
    "    # 损失可视化\n",
    "    model.plot_loss_curve()\n",
    "\n",
    "    # 决策边界可视化\n",
    "    model.plot_decision_boundary(X_train, y_train)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57375 0.27875] [0.49611111 0.12752222]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = np.loadtxt('../machine learning note/watermelon_3a.csv',delimiter=',')\n",
    "X = dataset[:,1:3]\n",
    "y = dataset[:,3]\n",
    "\n",
    "# 计算均值\n",
    "mean1 = np.mean(X[y == 1],axis = 0)\n",
    "mean0 = np.mean(X[y == 0],axis = 0)\n",
    "\n",
    "print(mean1,mean0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [6 8]]\n"
     ]
    }
   ],
   "source": [
    "# 计算类内误差\n",
    "Sw = np.zeros((2,2))\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 1:\n",
    "        Sw += np.outer((X[i]-mean1),(X[i]-mean1))\n",
    "    else:\n",
    "        Sw += np.outer((X[i]-mean0),(X[i]-mean0))\n",
    "\n",
    "# 计算LDA\n",
    "w = np.dot(np.linalg.inv(Sw),mean1-mean0)\n",
    "\n",
    "# 向量化优化版本\n",
    "mask = y == 1\n",
    "X1 = X[mask] - mean1  # 类别1的样本中心化\n",
    "X0 = X[~mask] - mean0 # 类别0的样本中心化\n",
    "\n",
    "# 计算协方差矩阵 (等价于外积求和)\n",
    "Sw = X1.T @ X1 + X0.T @ X0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
