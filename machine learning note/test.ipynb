{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "# 特征字典，后面用到了好多次，干脆当全局变量了\n",
    "featureDic = {\n",
    "    '色泽': ['浅白', '青绿', '乌黑'],\n",
    "    '根蒂': ['硬挺', '蜷缩', '稍蜷'],\n",
    "    '敲声': ['沉闷', '浊响', '清脆'],\n",
    "    '纹理': ['清晰', '模糊', '稍糊'],\n",
    "    '脐部': ['凹陷', '平坦', '稍凹'],\n",
    "    '触感': ['硬滑', '软粘']}\n",
    "\n",
    "\n",
    "def getDataSet():\n",
    "    \"\"\"\n",
    "    get watermelon data set 3.0 alpha.\n",
    "    :return: 编码好的数据集以及特征的字典。\n",
    "    \"\"\"\n",
    "    dataSet = [\n",
    "        ['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.697, 0.460, 1],\n",
    "        ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 0.774, 0.376, 1],\n",
    "        ['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.634, 0.264, 1],\n",
    "        ['青绿', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 0.608, 0.318, 1],\n",
    "        ['浅白', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.556, 0.215, 1],\n",
    "        ['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0.403, 0.237, 1],\n",
    "        ['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', 0.481, 0.149, 1],\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '硬滑', 0.437, 0.211, 1],\n",
    "        ['乌黑', '稍蜷', '沉闷', '稍糊', '稍凹', '硬滑', 0.666, 0.091, 0],\n",
    "        ['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', 0.243, 0.267, 0],\n",
    "        ['浅白', '硬挺', '清脆', '模糊', '平坦', '硬滑', 0.245, 0.057, 0],\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '软粘', 0.343, 0.099, 0],\n",
    "        ['青绿', '稍蜷', '浊响', '稍糊', '凹陷', '硬滑', 0.639, 0.161, 0],\n",
    "        ['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', 0.657, 0.198, 0],\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0.360, 0.370, 0],\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', 0.593, 0.042, 0],\n",
    "        ['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', 0.719, 0.103, 0]\n",
    "    ]\n",
    "\n",
    "    features = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '密度', '含糖量']\n",
    "    # features = ['color', 'root', 'knocks', 'texture', 'navel', 'touch', 'density', 'sugar']\n",
    "\n",
    "    # #得到特征值字典，本来用这个生成的特征字典，还是直接当全局变量方便\n",
    "    # featureDic = {}\n",
    "    # for i in range(len(features)):\n",
    "    #     featureList = [example[i] for example in dataSet]\n",
    "    #     uniqueFeature = list(set(featureList))\n",
    "    #     featureDic[features[i]] = uniqueFeature\n",
    "\n",
    "    # 每种特征的属性个数\n",
    "    numList = []  # [3, 3, 3, 3, 3, 2]\n",
    "    for i in range(len(features) - 2):\n",
    "        numList.append(len(featureDic[features[i]]))\n",
    "\n",
    "    dataSet = np.array(dataSet)\n",
    "    return dataSet[:, :-1], dataSet[:, -1], features\n",
    "\n",
    "\n",
    "# data, classLabel, feature = getDataSet()\n",
    "# print(data)\n",
    "# print(classLabel)\n",
    "# print(feature)\n",
    "\n",
    "\n",
    "def newData():\n",
    "    \"\"\"\n",
    "    利用pandas将分类变量转化为数值变量。将分类变量进行one-hot编码。\n",
    "    :return: 变量全为数值的变量，以及新的特征标签。\n",
    "    \"\"\"\n",
    "    dataSet, classLabel, features = getDataSet()\n",
    "    df = pd.DataFrame(dataSet)\n",
    "    df.columns = features\n",
    "    # 类别变量转化为数字变量\n",
    "    # features = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '密度', '含糖量']\n",
    "    # features = ['color', 'root', 'knocks', 'texture', 'navel', 'touch', 'density', 'sugar']\n",
    "    # 色泽\n",
    "    color = pd.get_dummies(df.色泽, prefix=\"色泽\")\n",
    "    # 根蒂\n",
    "    root = pd.get_dummies(df.根蒂, prefix=\"根蒂\")\n",
    "    # 敲声\n",
    "    knocks = pd.get_dummies(df.敲声, prefix=\"敲声\")\n",
    "    # 纹理\n",
    "    texture = pd.get_dummies(df.纹理, prefix=\"纹理\")\n",
    "    # 脐部\n",
    "    navel = pd.get_dummies(df.脐部, prefix=\"脐部\")\n",
    "    # 触感\n",
    "    touch = pd.get_dummies(df.触感, prefix=\"触感\")\n",
    "    # 密度和含糖量\n",
    "    densityAndsugar = pd.DataFrame()\n",
    "    densityAndsugar[\"密度\"] = df.密度\n",
    "    densityAndsugar[\"含糖量\"] = df.含糖量\n",
    "    # 融合\n",
    "    newData = pd.concat([color, root, knocks, texture, navel, touch, densityAndsugar], axis=1)\n",
    "    # print(\"newData\", newData)\n",
    "    newFeatures = list(newData.columns)\n",
    "    newData = np.asarray(newData, dtype=\"float64\")\n",
    "    classLabel = np.asarray(classLabel, dtype=\"int\").reshape(-1, 1)\n",
    "\n",
    "    # 新的特征数据和类融合\n",
    "    newDataSet = np.concatenate((newData, classLabel), axis=1)\n",
    "    # # 在第一列添加1\n",
    "    # newDataSet = np.insert(newDataSet, 0,\n",
    "    #                        np.ones(dataSet.shape[0]),\n",
    "    #                        axis=1)\n",
    "\n",
    "    return newDataSet, newFeatures\n",
    "\n",
    "\n",
    "# Sigmoid 函数\n",
    "def sigmoid(Z):\n",
    "    return 1.0 / (1 + np.exp(-Z))\n",
    "\n",
    "\n",
    "# 神经网络累计BP\n",
    "def NNetworkBP(dataSet, eta, thresh):\n",
    "    \"\"\"\n",
    "    :param dataSet: 数据集. m x n\n",
    "    :param eta: 学习率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    errHistory = []     # 记录每轮迭代的均方误差\n",
    "    y = dataSet[:, -1].reshape(-1, 1)\n",
    "    x = dataSet[:, :-1]\n",
    "    m, n = x.shape\n",
    "    # 隐层参数\n",
    "    v = np.random.randn(n, n + 1)\n",
    "    # 输出层参数\n",
    "    w = np.random.randn(n + 1, 1)\n",
    "    # 隐层阈值\n",
    "    gamma = np.random.randn(1, n + 1)\n",
    "    # 输出值\n",
    "    theta = np.random.random(1)\n",
    "\n",
    "    err = errOfMeanSqur(dataSet, v, gamma, w, theta)\n",
    "    while err > thresh:\n",
    "        b = sigmoid(np.dot(x, v) - gamma)  # m x (n+1)\n",
    "        beta = np.dot(b, w)     # m x 1\n",
    "        # 预测值\n",
    "        yHat = sigmoid(beta - theta)    # m x 1\n",
    "        # 输出层神经元梯度项\n",
    "        g = yHat * (1 - yHat) * (y - yHat)  # m x 1\n",
    "        # 隐层神经元梯度向\n",
    "        e = b * (1 - b) * np.dot(g, w.T)    # m x (n+1)\n",
    "        # 更新w, v, theta, gamma\n",
    "        w += eta * np.dot(b.T, g)\n",
    "        v += eta * np.dot(x.T, e)\n",
    "        theta -= eta * g.sum()\n",
    "        gamma -= eta * e.sum(axis=0)\n",
    "\n",
    "        err = errOfMeanSqur(dataSet, v, gamma, w, theta)\n",
    "        errHistory.append(err)\n",
    "\n",
    "    return v, gamma, w, theta, errHistory\n",
    "\n",
    "\n",
    "# 神经网络累计BP\n",
    "def NNetworkABP(dataSet, eta, thresh):\n",
    "    \"\"\"\n",
    "    :param dataSet: 数据集. m x n\n",
    "    :param eta: 学习率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    errHistory = []     # 记录每轮迭代的均方误差\n",
    "    y = dataSet[:, -1].reshape(-1, 1)\n",
    "    x = dataSet[:, :-1]\n",
    "    m, n = x.shape\n",
    "    # 隐层参数\n",
    "    v = np.random.randn(n, n + 1)\n",
    "    # 输出层参数\n",
    "    w = np.random.randn(n + 1, 1)\n",
    "    # 隐层阈值\n",
    "    gamma = np.random.randn(1, n + 1)\n",
    "    # 输出值\n",
    "    theta = np.random.random(1)\n",
    "    epoch = 0\n",
    "\n",
    "    err = errOfMeanSqur(dataSet, v, gamma, w, theta)\n",
    "    while err > thresh:\n",
    "        for i in range(m):\n",
    "            b = sigmoid(np.dot(x[i], v) - gamma)  # 1 x (n+1)\n",
    "            beta = np.dot(b, w)[0]     # 1\n",
    "            # 预测值\n",
    "            yHat = sigmoid(beta - theta)  # 1\n",
    "            # 输出层神经元梯度项\n",
    "            g = yHat * (1 - yHat) * (y[i] - yHat)  # 1\n",
    "            print(\"g = \", g)\n",
    "            # 隐层神经元梯度向\n",
    "            e = b * (1 - b) * g * w.T.sum()   # 1 x (n+1)\n",
    "            # 更新w, v, theta, gamma\n",
    "            w += eta * b.T * g\n",
    "            v += eta * np.dot(x[i].reshape(n, -1), e)\n",
    "            theta -= eta * g\n",
    "            gamma -= eta * e\n",
    "            epoch += 1\n",
    "            err = errOfMeanSqur(dataSet, v, gamma, w, theta)\n",
    "            errHistory.append(err)\n",
    "\n",
    "    return v, gamma, w, theta, errHistory\n",
    "\n",
    "\n",
    "def classify(data, v, gamma, w, theta):\n",
    "    b = sigmoid(np.dot(data, v) - gamma)\n",
    "    beta = np.dot(b, w)\n",
    "    yHat = sigmoid(beta - theta)\n",
    "    return yHat[0][0]\n",
    "\n",
    "\n",
    "def errOfMeanSqur(dataSet, v, gamma, w, theta):\n",
    "    x = dataSet[:, :-1]\n",
    "    y = dataSet[:, -1]\n",
    "    num = x.shape[0]\n",
    "    err = 0.0\n",
    "    for i in range(num):\n",
    "        yPre = classify(dataSet[i][:-1], v, gamma, w, theta)\n",
    "        err += ((y[i] - yPre) ** 2) / 2.0\n",
    "\n",
    "    return err / float(num)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # # test NNetwork\n",
    "    dataSet, _ = newData()\n",
    "    print(dataSet)\n",
    "    v1, gamma1, w1, theta1, errHistory1 = NNetworkBP(dataSet, 0.1, 0.001)\n",
    "    # 画图\n",
    "    plt.plot(np.arange(len(errHistory1)), errHistory1)\n",
    "    plt.show()\n",
    "    # test NNetworkABP(dataSet, eta, thresh)\n",
    "    v2, gamma2, w2, theta2, errHistory2 = NNetworkABP(dataSet, 0.1, 0.001)\n",
    "    plt.plot(np.arange(len(errHistory2)), errHistory2)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#西瓜数据集 每一列为一条数据\n",
    "features=np.array([\n",
    "    [1,2,2,1,0,1,2,2,2,1,0,0,1,0,2,0,1],\n",
    "    [2,2,2,2,2,1,1,1,1,0,0,2,1,1,1,2,2],\n",
    "    [1,0,1,0,1,1,1,1,0,2,2,1,1,0,1,1,0],\n",
    "    [0,0,0,0,0,0,1,0,1,0,2,2,1,1,0,2,1],\n",
    "    [2,2,2,2,2,1,1,1,1,0,0,0,2,2,1,0,1],\n",
    "    [1,1,1,1,1,0,0,1,1,0,1,0,1,1,0,1,1],\n",
    "    [0.697,0.774,0.634,0.608,0.556,0.403,0.481,0.437,0.666,0.243,0.245,0.343,0.639,0.657,0.360,0.593,0.719],\n",
    "    [0.460,0.376,0.264,0.318,0.215,0.237,0.149,0.211,0.091,0.267,0.057,0.099,0.161,0.198,0.370,0.042,0.103]\n",
    "])\n",
    "labels=np.array([\n",
    "    [1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0]\n",
    "])\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1./(1+np.exp(-X))\n",
    "class Net():\n",
    "    def __init__(self,num_input=8,num_hidden=10,num_output=1):\n",
    "        #隐含层和输出层的权重和偏置\n",
    "        self.W1=np.random.randn(num_hidden,num_input)\n",
    "        self.b1=np.zeros(num_hidden).reshape(-1,1)\n",
    "        self.W2=np.random.randn(num_output,num_hidden)\n",
    "        self.b2=np.zeros(num_output).reshape(-1,1)\n",
    "        #隐含层和输出层的输出\n",
    "        self.o1=np.zeros(num_hidden).reshape(-1,1)\n",
    "        self.o2=np.zeros(num_output).reshape(-1,1)\n",
    "        #梯度存储变量\n",
    "        self.do2=np.zeros(self.o2.shape)\n",
    "        self.dW2=np.zeros(self.W2.shape)\n",
    "        self.db2=np.zeros(self.b2.shape)\n",
    "        self.do1=np.zeros(self.o1.shape)\n",
    "        self.dW1=np.zeros(self.W1.shape)\n",
    "        self.db1=np.zeros(self.b1.shape)\n",
    "    def forward(self,X):#前向传播\n",
    "        if X.shape[0] != self.W1.shape[1]:\n",
    "            print(\"输入数据格式错误！\")\n",
    "            return\n",
    "        self.input=X\n",
    "        #使用sigmoid函数为激活函数\n",
    "        self.o1=sigmoid(np.matmul(self.W1,self.input)+self.b1)\n",
    "        self.o2=sigmoid(np.matmul(self.W2,self.o1)+self.b2)\n",
    "        return self.o2\n",
    "    def standard_BP(self,label,lr=0.2):#标准BP 使用均方误差为损失函数\n",
    "        #求梯度\n",
    "        self.do2=self.o2-label\n",
    "        self.dW2=np.matmul(self.do2*self.o2*(1-self.o2),self.o1.reshape(1,-1))\n",
    "        self.db2=self.do2*self.o2*(1-self.o2)\n",
    "        self.do1=np.matmul(self.W2.transpose(),self.do2*self.o2*(1-self.o2))\n",
    "        self.dW1=np.matmul(self.do1*self.o1*(1-self.o1),self.input.reshape(1,-1))\n",
    "        self.db1=self.do1*self.o1*(1-self.o1)\n",
    "        #更新参数\n",
    "        self.W2-=self.dW2*lr\n",
    "        self.b2-=self.db2*lr\n",
    "        self.W1-=self.dW1*lr\n",
    "        self.b1-=self.db1*lr\n",
    "    def accumulate_BP(self,labels,lr=0.2):#累积BP 使用均方误差为损失函数\n",
    "        num=labels.shape[1]#样本数量\n",
    "        #求梯度\n",
    "        self.do2=(self.o2-labels)/num\n",
    "        self.dW2=np.matmul(self.do2*self.o2*(1-self.o2),self.o1.transpose())\n",
    "        self.db2=(self.do2*self.o2*(1-self.o2)).sum(axis=1).reshape(-1,1)\n",
    "        self.do1=np.matmul(self.W2.transpose(),self.do2*self.o2*(1-self.o2))\n",
    "        self.dW1=np.matmul(self.do1*self.o1*(1-self.o1),self.input.transpose())\n",
    "        self.db1=(self.do1*self.o1*(1-self.o1)).sum(axis=1).reshape(-1,1)\n",
    "        #更新参数\n",
    "        self.W2-=self.dW2*lr\n",
    "        self.b2-=self.db2*lr\n",
    "        self.W1-=self.dW1*lr\n",
    "        self.b1-=self.db1*lr\n",
    "        \n",
    "def train_standard_BP(features,labels,lr):\n",
    "    net=Net()\n",
    "    epoch=0\n",
    "    loss=1\n",
    "    all_loss=[]\n",
    "    while loss>0.01:#停止条件\n",
    "        for i in range(features.shape[1]):\n",
    "            X=features[:,i]\n",
    "            Y=labels[0,i]\n",
    "            net.forward(X.reshape(-1,1))\n",
    "            net.standard_BP(Y,lr)\n",
    "        output=net.forward(features)\n",
    "        loss=0.5*((output-labels)**2).sum()\n",
    "        epoch+=1\n",
    "        all_loss.append(loss)\n",
    "    print(\"标准BP\",\"学习率：\",lr,\"\\n终止epoch：\",epoch,\"loss: \",loss)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(all_loss)\n",
    "    plt.show()\n",
    "    \n",
    "def train_accumulate_BP(features,labels,lr=0.2):\n",
    "    net=Net()\n",
    "    epoch=0\n",
    "    loss=1\n",
    "    all_loss=[]\n",
    "    while loss>0.01:#停止条件\n",
    "        output=net.forward(features)\n",
    "        net.accumulate_BP(labels,lr)\n",
    "        loss=0.5*((output-labels)**2).sum()/labels.shape[1]\n",
    "        epoch+=1\n",
    "        all_loss.append(loss)\n",
    "    print(\"累积BP\",\"学习率：\",lr,\"\\n终止epoch：\",epoch,\"loss: \",loss)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(all_loss)\n",
    "    plt.show()\n",
    "\n",
    "train_standard_BP(features,labels,0.1)\n",
    "train_accumulate_BP(features,labels,0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1, err = 27.598255718523475\n",
      "iteration 2, err = 26.882820717781332\n",
      "iteration 3, err = 0.5765954775101492\n",
      "iteration 4, err = 0.31209806831926507\n",
      "iteration 5, err = 0.14261484328489593\n",
      "iteration 6, err = 0.06396468302402102\n",
      "iteration 7, err = 0.06289612191353328\n",
      "iteration 8, err = 0.08609138712214127\n",
      "iteration 9, err = 0.06098221958061106\n",
      "iteration 10, err = 0.08111682404396105\n",
      "iteration 11, err = 0.1045536770536512\n",
      "iteration 12, err = 0.058329594056829775\n",
      "iteration 13, err = 0.058351867925893586\n",
      "iteration 14, err = 0.06452808102077698\n",
      "iteration 15, err = 0.0858100066849134\n",
      "iteration 16, err = 0.10173604336605463\n",
      "iteration 17, err = 0.055300909655681026\n",
      "iteration 18, err = 0.05648956581624648\n",
      "iteration 19, err = 0.07641672746006256\n",
      "iteration 20, err = 0.06828970588034809\n",
      "iteration 21, err = 0.08557730047657695\n",
      "iteration 22, err = 0.09511843001711956\n",
      "iteration 23, err = 0.0996324166781515\n",
      "iteration 24, err = 0.052056315943490805\n",
      "iteration 25, err = 0.054221887160681666\n",
      "iteration 26, err = 0.05630434480728784\n",
      "iteration 27, err = 0.0747612299105211\n",
      "iteration 28, err = 0.05373617245860871\n",
      "iteration 29, err = 0.07332265611567607\n",
      "iteration 30, err = 0.056149323621485975\n",
      "iteration 31, err = 0.053346853098396\n",
      "iteration 32, err = 0.053685264063572005\n",
      "iteration 33, err = 0.06558950767819118\n",
      "iteration 34, err = 0.08347230450218718\n",
      "iteration 35, err = 0.0958717442451945\n",
      "iteration 36, err = 0.053600120263501555\n",
      "iteration 37, err = 0.06075768401422099\n",
      "iteration 38, err = 0.05679842307718975\n",
      "iteration 39, err = 0.07463828773109513\n",
      "iteration 40, err = 0.0508662090040354\n",
      "iteration 41, err = 0.060202520210430856\n",
      "iteration 42, err = 0.05238873494256446\n",
      "iteration 43, err = 0.05676472468209659\n",
      "iteration 44, err = 0.057467057334337567\n",
      "iteration 45, err = 0.0729403444026795\n",
      "iteration 46, err = 0.0671244681228333\n",
      "iteration 47, err = 0.0487719432751963\n",
      "iteration 48, err = 0.04823035536460838\n",
      "iteration 49, err = 0.06231448625537201\n",
      "iteration 50, err = 0.0616166484104949\n",
      "iteration 51, err = 0.04979733797870768\n",
      "iteration 52, err = 0.06915524456168799\n",
      "iteration 53, err = 0.08924392583769361\n",
      "iteration 54, err = 0.05459022509865573\n",
      "iteration 55, err = 0.04844444724191857\n",
      "iteration 56, err = 0.06255275341170256\n",
      "iteration 57, err = 0.051345829381517626\n",
      "iteration 58, err = 0.06769652909507261\n",
      "iteration 59, err = 0.0786647312432901\n",
      "iteration 60, err = 0.04592878285923545\n",
      "iteration 61, err = 0.0597678978153972\n",
      "iteration 62, err = 0.0779321193094444\n",
      "iteration 63, err = 0.09020033130063215\n",
      "iteration 64, err = 0.04489335522539349\n",
      "iteration 65, err = 0.04797335613303954\n",
      "iteration 66, err = 0.05065492981187465\n",
      "iteration 67, err = 0.044789031171578716\n",
      "iteration 68, err = 0.05583088156780598\n",
      "iteration 69, err = 0.047539526470857074\n",
      "iteration 70, err = 0.06458297906343813\n",
      "iteration 71, err = 0.04718697516388857\n",
      "iteration 72, err = 0.05222675735277445\n",
      "iteration 73, err = 0.06628135826388207\n",
      "iteration 74, err = 0.043886977620898195\n",
      "iteration 75, err = 0.051892588136629975\n",
      "iteration 76, err = 0.05398086923976811\n",
      "iteration 77, err = 0.04483526043084278\n",
      "iteration 78, err = 0.04322703849254237\n",
      "iteration 79, err = 0.055222201326814525\n",
      "iteration 80, err = 0.04525751856391477\n",
      "iteration 81, err = 0.04273783619755104\n",
      "iteration 82, err = 0.053211895803716276\n",
      "iteration 83, err = 0.045118259585837095\n",
      "iteration 84, err = 0.048395423358456834\n",
      "iteration 85, err = 0.050627583465375874\n",
      "iteration 86, err = 0.06278190036380547\n",
      "iteration 87, err = 0.04266631493119759\n",
      "iteration 88, err = 0.05800568435738672\n",
      "iteration 89, err = 0.07354874898920696\n",
      "iteration 90, err = 0.04113131564983322\n",
      "iteration 91, err = 0.0494156222159942\n",
      "iteration 92, err = 0.043029175012211235\n",
      "iteration 93, err = 0.04542229327561997\n",
      "iteration 94, err = 0.060978011491306834\n",
      "iteration 95, err = 0.04075919780126409\n",
      "iteration 96, err = 0.04624537006821458\n",
      "iteration 97, err = 0.0518668659524165\n",
      "iteration 98, err = 0.05901124986198275\n",
      "iteration 99, err = 0.041098116776193745\n",
      "iteration 100, err = 0.04423915365296989\n",
      "iteration 101, err = 0.05325798375233051\n",
      "iteration 102, err = 0.04133004508461842\n",
      "iteration 103, err = 0.056563625053000714\n",
      "iteration 104, err = 0.0394667160945543\n",
      "iteration 105, err = 0.04513949572295415\n",
      "iteration 106, err = 0.04129560978390351\n",
      "iteration 107, err = 0.039099978798171814\n",
      "iteration 108, err = 0.04832404208167317\n",
      "iteration 109, err = 0.03961425645253245\n",
      "iteration 110, err = 0.05252414786481399\n",
      "iteration 111, err = 0.06596786082706617\n",
      "iteration 112, err = 0.038372625186113916\n",
      "iteration 113, err = 0.04324994319577807\n",
      "iteration 114, err = 0.04040957387471017\n",
      "iteration 115, err = 0.05906962117465403\n",
      "iteration 116, err = 0.07591434662857949\n",
      "iteration 117, err = 0.03771000846231944\n",
      "iteration 118, err = 0.04136846106859743\n",
      "iteration 119, err = 0.04901094439376523\n",
      "iteration 120, err = 0.05475374119282797\n",
      "iteration 121, err = 0.0566146341061981\n",
      "iteration 122, err = 0.05743967728803672\n",
      "iteration 123, err = 0.0577982144329472\n",
      "iteration 124, err = 0.03712858300129279\n",
      "iteration 125, err = 0.04049914635671255\n",
      "iteration 126, err = 0.04630066643539763\n",
      "iteration 127, err = 0.052946619086016035\n",
      "iteration 128, err = 0.03810802544081902\n",
      "iteration 129, err = 0.05441537826924292\n",
      "iteration 130, err = 0.03657315258734143\n",
      "iteration 131, err = 0.03640538801444992\n",
      "iteration 132, err = 0.038999929876772664\n",
      "iteration 133, err = 0.04116303596517927\n",
      "iteration 134, err = 0.05554708720974347\n",
      "iteration 135, err = 0.06645337289186534\n",
      "iteration 136, err = 0.035331217917575895\n",
      "iteration 137, err = 0.04270258254268884\n",
      "iteration 138, err = 0.03703832644456542\n",
      "iteration 139, err = 0.04649216341572271\n",
      "iteration 140, err = 0.03606488594345815\n",
      "iteration 141, err = 0.03835564328113252\n",
      "iteration 142, err = 0.03793922767301086\n",
      "iteration 143, err = 0.03659150715828001\n",
      "iteration 144, err = 0.041169531232122435\n",
      "iteration 145, err = 0.04855573503049495\n",
      "iteration 146, err = 0.04992103654920694\n",
      "iteration 147, err = 0.033795445175820754\n",
      "iteration 148, err = 0.03475932856466318\n",
      "iteration 149, err = 0.04352041034293153\n",
      "iteration 150, err = 0.046175871538979105\n",
      "iteration 151, err = 0.034253963489017734\n",
      "iteration 152, err = 0.04766629780298662\n",
      "iteration 153, err = 0.061887305076497263\n",
      "iteration 154, err = 0.035866723218761234\n",
      "iteration 155, err = 0.03296698921430702\n",
      "iteration 156, err = 0.04122384934500273\n",
      "iteration 157, err = 0.03512877765814631\n",
      "iteration 158, err = 0.04501304294928823\n",
      "iteration 159, err = 0.051485172677507185\n",
      "iteration 160, err = 0.03207711526285632\n",
      "iteration 161, err = 0.042862730189027774\n",
      "iteration 162, err = 0.05566104136000897\n",
      "iteration 163, err = 0.06407674770625728\n",
      "iteration 164, err = 0.031326447690907554\n",
      "iteration 165, err = 0.034086560795597264\n",
      "iteration 166, err = 0.0351066472318192\n",
      "iteration 167, err = 0.031197217760061603\n",
      "iteration 168, err = 0.038885038411025315\n",
      "iteration 169, err = 0.03318546177953579\n",
      "iteration 170, err = 0.04524669695265751\n",
      "iteration 171, err = 0.03198227629205844\n",
      "iteration 172, err = 0.036094759196230564\n",
      "iteration 173, err = 0.04481405799798265\n",
      "iteration 174, err = 0.030744850141130167\n",
      "iteration 175, err = 0.03515289514277169\n",
      "iteration 176, err = 0.038218734198041227\n",
      "iteration 177, err = 0.031301120919853945\n",
      "iteration 178, err = 0.030320257863800246\n",
      "iteration 179, err = 0.03839694791599279\n",
      "iteration 180, err = 0.03152934836026048\n",
      "iteration 181, err = 0.02976172985758645\n",
      "iteration 182, err = 0.03675307785078965\n",
      "iteration 183, err = 0.031185931091037497\n",
      "iteration 184, err = 0.03424449402902725\n",
      "iteration 185, err = 0.036452472676035096\n",
      "iteration 186, err = 0.04385915123779185\n",
      "iteration 187, err = 0.029609556012590837\n",
      "iteration 188, err = 0.04078553693267849\n",
      "iteration 189, err = 0.05119953247865336\n",
      "iteration 190, err = 0.02855787566078816\n",
      "iteration 191, err = 0.03497378542853523\n",
      "iteration 192, err = 0.02968264058159902\n",
      "iteration 193, err = 0.032300138285435286\n",
      "iteration 194, err = 0.043704083931344895\n",
      "iteration 195, err = 0.028389277212187508\n",
      "iteration 196, err = 0.032609861868750575\n",
      "iteration 197, err = 0.03730988139515951\n",
      "iteration 198, err = 0.041116236595799195\n",
      "iteration 199, err = 0.02857867880265853\n",
      "iteration 200, err = 0.030579734471706345\n",
      "iteration 201, err = 0.03641262733597609\n",
      "iteration 202, err = 0.028899065955710932\n",
      "iteration 203, err = 0.04008139166570011\n",
      "iteration 204, err = 0.027413807645831633\n",
      "iteration 205, err = 0.03174924827586274\n",
      "iteration 206, err = 0.028857222608473298\n",
      "iteration 207, err = 0.02732665656812596\n",
      "iteration 208, err = 0.033482155423785534\n",
      "iteration 209, err = 0.027724652825595993\n",
      "iteration 210, err = 0.037318600005866336\n",
      "iteration 211, err = 0.047026210788313566\n",
      "iteration 212, err = 0.026684352784818722\n",
      "iteration 213, err = 0.03026019930776854\n",
      "iteration 214, err = 0.02816956429246871\n",
      "iteration 215, err = 0.040905027945458035\n",
      "iteration 216, err = 0.0521066848685707\n",
      "iteration 217, err = 0.026213272840345227\n",
      "iteration 218, err = 0.029066043754822787\n",
      "iteration 219, err = 0.03388289293181348\n",
      "iteration 220, err = 0.038543095959172095\n",
      "iteration 221, err = 0.039031242539843074\n",
      "iteration 222, err = 0.03924035766066189\n",
      "iteration 223, err = 0.03932927484299365\n",
      "iteration 224, err = 0.025769099753603784\n",
      "iteration 225, err = 0.027977758558747595\n",
      "iteration 226, err = 0.03236130393815361\n",
      "iteration 227, err = 0.036543679151685125\n",
      "iteration 228, err = 0.026237531039669967\n",
      "iteration 229, err = 0.037150068050538214\n",
      "iteration 230, err = 0.02503079568120808\n",
      "iteration 231, err = 0.02529065761025709\n",
      "iteration 232, err = 0.027314690461897752\n",
      "iteration 233, err = 0.027957959884924017\n",
      "iteration 234, err = 0.03748299774897549\n",
      "iteration 235, err = 0.044691549952245516\n",
      "iteration 236, err = 0.024389039912175257\n",
      "iteration 237, err = 0.029654525023003288\n",
      "iteration 238, err = 0.025383700560214585\n",
      "iteration 239, err = 0.03171771803853165\n",
      "iteration 240, err = 0.024787946440606147\n",
      "iteration 241, err = 0.02629829162176784\n",
      "iteration 242, err = 0.026003052678537843\n",
      "iteration 243, err = 0.02511933324708201\n",
      "iteration 244, err = 0.028632232257790487\n",
      "iteration 245, err = 0.033325675574598895\n",
      "iteration 246, err = 0.034719413841319484\n",
      "iteration 247, err = 0.02330184145678308\n",
      "iteration 248, err = 0.023911946032894517\n",
      "iteration 249, err = 0.02981803582245906\n",
      "iteration 250, err = 0.03198508342069056\n",
      "iteration 251, err = 0.02338528663700946\n",
      "iteration 252, err = 0.033067416171719835\n",
      "iteration 253, err = 0.043453693337317495\n",
      "iteration 254, err = 0.024548012640773508\n",
      "iteration 255, err = 0.022619780527683223\n",
      "iteration 256, err = 0.027892555078349802\n",
      "iteration 257, err = 0.024202905954350148\n",
      "iteration 258, err = 0.03090273296149617\n",
      "iteration 259, err = 0.03515925506807114\n",
      "iteration 260, err = 0.022060790381517453\n",
      "iteration 261, err = 0.030286339500219337\n",
      "iteration 262, err = 0.03831566199251532\n",
      "iteration 263, err = 0.043355292935685116\n",
      "iteration 264, err = 0.02142173377000399\n",
      "iteration 265, err = 0.02354860494387004\n",
      "iteration 266, err = 0.024137193828029382\n",
      "iteration 267, err = 0.021317781571061477\n",
      "iteration 268, err = 0.02659360648633871\n",
      "iteration 269, err = 0.022571218388737577\n",
      "iteration 270, err = 0.030484181907399342\n",
      "iteration 271, err = 0.021654517736534405\n",
      "iteration 272, err = 0.02483077879024744\n",
      "iteration 273, err = 0.03062773356228497\n",
      "iteration 274, err = 0.02110378073645001\n",
      "iteration 275, err = 0.02375203872180688\n",
      "iteration 276, err = 0.026142178194905084\n",
      "iteration 277, err = 0.021501910564890342\n",
      "iteration 278, err = 0.02063910864559164\n",
      "iteration 279, err = 0.02611729117098784\n",
      "iteration 280, err = 0.021401575759871404\n",
      "iteration 281, err = 0.020303863335833627\n",
      "iteration 282, err = 0.025248556286207476\n",
      "iteration 283, err = 0.02115276443295723\n",
      "iteration 284, err = 0.023426763450695064\n",
      "iteration 285, err = 0.025079201149934872\n",
      "iteration 286, err = 0.02991612451324518\n",
      "iteration 287, err = 0.020077050899682834\n",
      "iteration 288, err = 0.028128847346589575\n",
      "iteration 289, err = 0.034638968811754184\n",
      "iteration 290, err = 0.01939789633726184\n",
      "iteration 291, err = 0.024053144477888685\n",
      "iteration 292, err = 0.020056809977335582\n",
      "iteration 293, err = 0.022289051763388246\n",
      "iteration 294, err = 0.030539588923718358\n",
      "iteration 295, err = 0.019210196808665408\n",
      "iteration 296, err = 0.022232691652142336\n",
      "iteration 297, err = 0.025716838253850422\n",
      "iteration 298, err = 0.027883958190558254\n",
      "iteration 299, err = 0.019309617836679907\n",
      "iteration 300, err = 0.020684321898323192\n",
      "iteration 301, err = 0.02450130555749673\n",
      "iteration 302, err = 0.019554865768426802\n",
      "iteration 303, err = 0.027587737886403337\n",
      "iteration 304, err = 0.018526733127499872\n",
      "iteration 305, err = 0.021657888641531828\n",
      "iteration 306, err = 0.019661403078302275\n",
      "iteration 307, err = 0.0185004305988387\n",
      "iteration 308, err = 0.022596354477377466\n",
      "iteration 309, err = 0.01889489020782801\n",
      "iteration 310, err = 0.02591347903051376\n",
      "iteration 311, err = 0.0327834000958824\n",
      "iteration 312, err = 0.018007443649329866\n",
      "iteration 313, err = 0.020522935771648588\n",
      "iteration 314, err = 0.019127508162240896\n",
      "iteration 315, err = 0.027570407256844634\n",
      "iteration 316, err = 0.03471974919566465\n",
      "iteration 317, err = 0.01766945902494856\n",
      "iteration 318, err = 0.01985023136256153\n",
      "iteration 319, err = 0.022862230291251638\n",
      "iteration 320, err = 0.026308727648348507\n",
      "iteration 321, err = 0.02623822398303068\n",
      "iteration 322, err = 0.026208987353654737\n",
      "iteration 323, err = 0.026196844337858516\n",
      "iteration 324, err = 0.01740755972365049\n",
      "iteration 325, err = 0.018750302511712502\n",
      "iteration 326, err = 0.021882272068008544\n",
      "iteration 327, err = 0.0245576457941916\n",
      "iteration 328, err = 0.01759043315120254\n",
      "iteration 329, err = 0.024698068040032765\n",
      "iteration 330, err = 0.016723696285376826\n",
      "iteration 331, err = 0.017121279638075127\n",
      "iteration 332, err = 0.01859202996407944\n",
      "iteration 333, err = 0.018593390570732\n",
      "iteration 334, err = 0.024727813117286036\n",
      "iteration 335, err = 0.02932468825631313\n",
      "iteration 336, err = 0.016453036500650737\n",
      "iteration 337, err = 0.020077062826166635\n",
      "iteration 338, err = 0.017001506885451847\n",
      "iteration 339, err = 0.021200707492371417\n",
      "iteration 340, err = 0.016601712016602904\n",
      "iteration 341, err = 0.017634179002167617\n",
      "iteration 342, err = 0.01736540001608663\n",
      "iteration 343, err = 0.016858365543766934\n",
      "iteration 344, err = 0.019415932101236256\n",
      "iteration 345, err = 0.022359074495655974\n",
      "iteration 346, err = 0.023502553664169926\n",
      "iteration 347, err = 0.015690867448550666\n",
      "iteration 348, err = 0.01601269794722001\n",
      "iteration 349, err = 0.01993891384876338\n",
      "iteration 350, err = 0.021562907469668692\n",
      "iteration 351, err = 0.01559844913278413\n",
      "iteration 352, err = 0.022446251839835906\n",
      "iteration 353, err = 0.029823601398160024\n",
      "iteration 354, err = 0.016411460034506355\n",
      "iteration 355, err = 0.015150390795236906\n",
      "iteration 356, err = 0.018464045197111267\n",
      "iteration 357, err = 0.01630174383752161\n",
      "iteration 358, err = 0.020773246222404996\n",
      "iteration 359, err = 0.023517595700088795\n",
      "iteration 360, err = 0.014826680361878387\n",
      "iteration 361, err = 0.02090978788723231\n",
      "iteration 362, err = 0.02573267632977399\n",
      "iteration 363, err = 0.028615993013931015\n",
      "iteration 364, err = 0.014296438270469548\n",
      "iteration 365, err = 0.015887517192499624\n",
      "iteration 366, err = 0.01620646418738425\n",
      "iteration 367, err = 0.01421390855632233\n",
      "iteration 368, err = 0.017769512148095065\n",
      "iteration 369, err = 0.014994670798879374\n",
      "iteration 370, err = 0.020080401792704882\n",
      "iteration 371, err = 0.014338687673257274\n",
      "iteration 372, err = 0.01669898121219921\n",
      "iteration 373, err = 0.020483684718594228\n",
      "iteration 374, err = 0.014156427790516101\n",
      "iteration 375, err = 0.015695781970947887\n",
      "iteration 376, err = 0.01745620915488121\n",
      "iteration 377, err = 0.014435054195114799\n",
      "iteration 378, err = 0.013710006375105187\n",
      "iteration 379, err = 0.01735980840753959\n",
      "iteration 380, err = 0.014194113475322885\n",
      "iteration 381, err = 0.013526747002342594\n",
      "iteration 382, err = 0.01696192638506703\n",
      "iteration 383, err = 0.014019661227505082\n",
      "iteration 384, err = 0.01564775706928864\n",
      "iteration 385, err = 0.016830156072649986\n",
      "iteration 386, err = 0.019929725573005864\n",
      "iteration 387, err = 0.013305180480893915\n",
      "iteration 388, err = 0.018973274940328775\n",
      "iteration 389, err = 0.022914217771192947\n",
      "iteration 390, err = 0.012873100174082837\n",
      "iteration 391, err = 0.016148073886872397\n",
      "iteration 392, err = 0.013250902380277015\n",
      "iteration 393, err = 0.015016536495057626\n",
      "iteration 394, err = 0.020810871384028387\n",
      "iteration 395, err = 0.012707341929765146\n",
      "iteration 396, err = 0.014822994907141967\n",
      "iteration 397, err = 0.017320721589317897\n",
      "iteration 398, err = 0.018478117570487836\n",
      "iteration 399, err = 0.012758293594125659\n",
      "iteration 400, err = 0.013671820910031258\n",
      "iteration 401, err = 0.016123442885218473\n",
      "iteration 402, err = 0.01294073995794777\n",
      "iteration 403, err = 0.018562188589169144\n",
      "iteration 404, err = 0.012241546007229591\n",
      "iteration 405, err = 0.014446009002099828\n",
      "iteration 406, err = 0.013093341407577543\n",
      "iteration 407, err = 0.012242265281697253\n",
      "iteration 408, err = 0.0149154457257796\n",
      "iteration 409, err = 0.01259223199228401\n",
      "iteration 410, err = 0.01757027863135495\n",
      "iteration 411, err = 0.02228862542704847\n",
      "iteration 412, err = 0.011882284080404246\n",
      "iteration 413, err = 0.013620910941681117\n",
      "iteration 414, err = 0.012693739192064894\n",
      "iteration 415, err = 0.018176349482350404\n",
      "iteration 416, err = 0.022648434668446724\n",
      "iteration 417, err = 0.01164509796167381\n",
      "iteration 418, err = 0.013261647741344956\n",
      "iteration 419, err = 0.015088309707133676\n",
      "iteration 420, err = 0.017548796020814963\n",
      "iteration 421, err = 0.017246082281466665\n",
      "iteration 422, err = 0.017124737847795134\n",
      "iteration 423, err = 0.01707560028661788\n",
      "iteration 424, err = 0.011515961130541841\n",
      "iteration 425, err = 0.012289866908358728\n",
      "iteration 426, err = 0.014463778234060571\n",
      "iteration 427, err = 0.01614241955431648\n",
      "iteration 428, err = 0.011544390167188352\n",
      "iteration 429, err = 0.016099141596443586\n",
      "iteration 430, err = 0.01094205100576229\n",
      "iteration 431, err = 0.011336726915533819\n",
      "iteration 432, err = 0.01236452333109168\n",
      "iteration 433, err = 0.01212667751087648\n",
      "iteration 434, err = 0.01601170341005577\n",
      "iteration 435, err = 0.01888520891817364\n",
      "iteration 436, err = 0.010866843366685655\n",
      "iteration 437, err = 0.01329480762788592\n",
      "iteration 438, err = 0.011151516791066718\n",
      "iteration 439, err = 0.013887692392852098\n",
      "iteration 440, err = 0.010887011172913554\n",
      "iteration 441, err = 0.011577403783288937\n",
      "iteration 442, err = 0.011362082270736802\n",
      "iteration 443, err = 0.011077260330551574\n",
      "iteration 444, err = 0.012879241864388755\n",
      "iteration 445, err = 0.014687861484989654\n",
      "iteration 446, err = 0.015555042758927051\n",
      "iteration 447, err = 0.010349791812513767\n",
      "iteration 448, err = 0.010493523016942731\n",
      "iteration 449, err = 0.013059417862685486\n",
      "iteration 450, err = 0.014221160400067075\n",
      "iteration 451, err = 0.010197451650955423\n",
      "iteration 452, err = 0.014923538403711911\n",
      "iteration 453, err = 0.020009135581474116\n",
      "iteration 454, err = 0.010740162287389958\n",
      "iteration 455, err = 0.009937039348008204\n",
      "iteration 456, err = 0.011990811948821022\n",
      "iteration 457, err = 0.010755003329144513\n",
      "iteration 458, err = 0.01368477259592995\n",
      "iteration 459, err = 0.015420842261445666\n",
      "iteration 460, err = 0.00976795950890561\n",
      "iteration 461, err = 0.014112044745412191\n",
      "iteration 462, err = 0.01691619349254199\n",
      "iteration 463, err = 0.018517799786746954\n",
      "iteration 464, err = 0.009348070443026279\n",
      "iteration 465, err = 0.01049869404217655\n",
      "iteration 466, err = 0.010656743699901097\n",
      "iteration 467, err = 0.009283848799353449\n",
      "iteration 468, err = 0.011636900144341863\n",
      "iteration 469, err = 0.009767503579705019\n",
      "iteration 470, err = 0.012990308913888516\n",
      "iteration 471, err = 0.0093164915864577\n",
      "iteration 472, err = 0.011001596014398977\n",
      "iteration 473, err = 0.013429480860885594\n",
      "iteration 474, err = 0.009308883127258683\n",
      "iteration 475, err = 0.010178428039757987\n",
      "iteration 476, err = 0.011423298806404737\n",
      "iteration 477, err = 0.009497006807331364\n",
      "iteration 478, err = 0.008925534115692649\n",
      "iteration 479, err = 0.011316339348162306\n",
      "iteration 480, err = 0.009233313586067228\n",
      "iteration 481, err = 0.008831813092195627\n",
      "iteration 482, err = 0.011168289429659979\n",
      "iteration 483, err = 0.009113634129549238\n",
      "iteration 484, err = 0.010243287099454497\n",
      "iteration 485, err = 0.01106001858704724\n",
      "iteration 486, err = 0.013012034300204067\n",
      "iteration 487, err = 0.008649668165454349\n",
      "iteration 488, err = 0.012542814412880986\n",
      "iteration 489, err = 0.014875684873276698\n",
      "iteration 490, err = 0.008377854317464958\n",
      "iteration 491, err = 0.010616574975784842\n",
      "iteration 492, err = 0.008591848910265421\n",
      "iteration 493, err = 0.009906213022918798\n",
      "iteration 494, err = 0.013859083723572443\n",
      "iteration 495, err = 0.008249571313364392\n",
      "iteration 496, err = 0.009698690931222057\n",
      "iteration 497, err = 0.011435580146245643\n",
      "iteration 498, err = 0.012009571268164598\n",
      "iteration 499, err = 0.008275370969110083\n",
      "iteration 500, err = 0.008864736705044302\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 1], label = 1, pre = [[0.79768924]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [1 1], label = 0, pre = [[0.06894623]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n",
      "data = [1 0], label = 1, pre = [[0.81318256]]\n",
      "data = [0 0], label = 0, pre = [[0.05274771]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getDataSet():\n",
    "    \"\"\"\n",
    "    得到异或的训练集\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataSet = [\n",
    "        [0, 0, 0],\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 0, 1]\n",
    "    ]\n",
    "    return np.array(dataSet)\n",
    "\n",
    "\n",
    "def RBFNN(dataSet, eta, thresh):\n",
    "    \"\"\"\n",
    "    训练RBF网络\n",
    "    :param dataSet: 数据集\n",
    "    :param eta:     学习率\n",
    "    :param thresh:  错误率容忍度\n",
    "    :return: w,     隐层神经元对应的权重\n",
    "             c,     隐层神经元对应的中心\n",
    "            beta,   高斯径向基函数里的参数\n",
    "          errHistory  训练的历史错误率\n",
    "    \"\"\"\n",
    "    errHistory = []  # 记录每轮迭代的均方误差\n",
    "    y = dataSet[:, -1]\n",
    "    x = dataSet[:, :-1]\n",
    "    m, n = x.shape\n",
    "\n",
    "    # 隐层神经元数\n",
    "    t = 10\n",
    "    # 初始化c\n",
    "    c = np.random.rand(t, n)\n",
    "    # 初始化beta\n",
    "    beta = np.random.randn(1, t)\n",
    "    # 初始化w\n",
    "    w = np.random.rand(1, t)\n",
    "    err = errOfMeanSqur(dataSet, w, c, beta)\n",
    "    while err > thresh:\n",
    "        for i in range(m):\n",
    "            trainX = np.tile(x[i], (t, 1))\n",
    "            dist = ((trainX - c) ** 2).sum(axis=1).reshape(1, -1)  # 1 x 8\n",
    "            rho = np.exp(-beta * dist)  # 1 x 8\n",
    "            phi = np.dot(w, rho.T)\n",
    "\n",
    "            # 计算梯度\n",
    "            dBeta = -w * (phi - y[i]) * rho * dist\n",
    "            dw = (phi - y[i]) * rho\n",
    "\n",
    "            # 更新参数\n",
    "            beta -= eta * dBeta\n",
    "            w -= eta * dw\n",
    "\n",
    "            # 计算新的错误率\n",
    "            err = errOfMeanSqur(dataSet, w, c, beta)\n",
    "            errHistory.append(err)\n",
    "            print(f\"iteration {len(errHistory)}, err = {err}\")\n",
    "\n",
    "    return w, c, beta, errHistory\n",
    "\n",
    "\n",
    "def classify(data, w, c, beta):\n",
    "    \"\"\"\n",
    "    给定参数分类\n",
    "    :param data:\n",
    "    :param w:\n",
    "    :param c:\n",
    "    :param beta:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataArr = np.tile(data, (c.shape[0], 1))\n",
    "    dist = ((dataArr - c) ** 2).sum(axis=1)\n",
    "    rho = np.exp(-beta * dist).reshape(-1, 1)\n",
    "    return np.dot(w, rho)\n",
    "\n",
    "\n",
    "def errOfMeanSqur(dataSet, w, c, beta):\n",
    "    \"\"\"\n",
    "    计算平方误差\n",
    "    :param dataSet:\n",
    "    :param w:\n",
    "    :param c:\n",
    "    :param beta:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = dataSet[:, :-1]\n",
    "    y = dataSet[:, -1]\n",
    "    num = x.shape[0]\n",
    "    err = 0.0\n",
    "    for i in range(num):\n",
    "        yPre = classify(dataSet[i][:-1],  w, c, beta)\n",
    "        err += ((y[i] - yPre) ** 2) / 2.0\n",
    "\n",
    "    return (err / float(num))[0][0]\n",
    "\n",
    "\n",
    "def main():\n",
    "    # test RBFNN(dataSet, eta, thresh)\n",
    "    X = np.random.randint(0,2,(100,2))\n",
    "    y = np.logical_xor(X[:,0],X[:,1]).astype(int)\n",
    "    dataSet = np.hstack((X,y.reshape(-1,1)))\n",
    "    # dataSet = getDataSet()\n",
    "    w, c, beta, errHistory1 = RBFNN(dataSet, 0.1, 0.01)\n",
    "    plt.plot(np.arange(len(errHistory1)), errHistory1)\n",
    "    plt.show()\n",
    "\n",
    "    # 测试抑或\n",
    "    for data in dataSet:\n",
    "        pre = classify(data[:-1], w, c, beta)\n",
    "        print(f\"data = {data[:-1]}, label = {data[-1]}, pre = {pre}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 2\n",
      "Epoch 1\n",
      "quantization_error= 0.4345\n",
      "Epoch 2\n",
      "quantization_error= 0.3283\n",
      "Epoch 3\n",
      "quantization_error= 0.2729\n",
      "Epoch 4\n",
      "quantization_error= 0.2356\n",
      "Epoch 5\n",
      "quantization_error= 0.2110\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.033664477831346e-43\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGiCAYAAADjixw0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKkFJREFUeJzt3X9Q1Nd+//HXGnSxc92NWIH1CxLjdVC0cTQawR8kXhV/REcnaaTTKVdSTa4t/ojMbXNxzE38I8XMTVKhOiZpiYxzR7TJgtBRE8koS7yiUy2Y2zSxemOqJUtNprqrdMQQz/cPrntd+SG7Csrx+Zj5TPicz/t8OCfrcV9+9rO7DmOMEQAAgMX63esBAAAA9DQCDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwXkSBZ9u2bXrsscfkcrnkcrmUkZGh/fv3d9nH5/Pp8ccfV2xsrB599FG988477Wq8Xq/S0tLkdDqVlpamioqKyGYBAADQhYgCT1JSkjZt2qTjx4/r+PHj+slPfqLFixfr888/77D+7NmzWrBggWbMmKH6+nqtX79ea9askdfrDdXU1dUpOztbOTk5OnnypHJycrR06VIdO3bszmYGAADwe447/fLQuLg4/epXv9Ly5cvbHXv55ZdVVVWlL774ItS2cuVKnTx5UnV1dZKk7OxsBYPBsCtF8+bN0+DBg1VWVnYnQwMAAJAkxUTb8YcfftAHH3yg5uZmZWRkdFhTV1enrKyssLa5c+eqpKRE33//vfr376+6ujqtW7euXc3mzZu7/P0tLS1qaWkJ7V+/fl3/+7//qyFDhsjhcEQ3KQAA0KuMMbp8+bKGDRumfv167tbiiAPPb3/7W2VkZOjq1av60Y9+pIqKCqWlpXVY29TUpISEhLC2hIQEtba26rvvvpPH4+m0pqmpqctxFBYWauPGjZEOHwAA3IfOnz+vpKSkHjt/xIEnNTVVDQ0NunTpkrxer5YtWyafz9dp6Ln1asuNV9Bubu+o5nZXaQoKCpSfnx/aDwQCGj58uM6fPy+XyxXRnAAAwL0RDAaVnJysQYMG9ejviTjwDBgwQD/+8Y8lSZMmTdK//uu/qqioSO+++2672sTExHZXai5cuKCYmBgNGTKky5pbr/rcyul0yul0tmu/8Q4yAADQd/T07Sh3/GKZMSbsXpqbZWRkqLq6OqztwIEDmjRpkvr3799lzdSpU+90aAAAAJIivMKzfv16zZ8/X8nJybp8+bJ27dqlmpoaffTRR5LaXmZqbGzUjh07JLW9I2vLli3Kz8/XCy+8oLq6OpWUlIS9+2rt2rXKzMzUG2+8ocWLF6uyslKffPKJDh8+fBenCQAAHmQRBZ7/+Z//UU5Ojvx+v9xutx577DF99NFHmjNnjiTJ7/fr3LlzofoRI0Zo3759WrdunbZu3aphw4apuLhYzz77bKhm6tSp2rVrlzZs2KBXXnlFI0eO1O7duzVlypS7NEUAAPCgu+PP4blfBINBud1uBQIB7uEBAKCP6K3nb75LCwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWiyjwFBYWavLkyRo0aJDi4+O1ZMkSnTp1qss+ubm5cjgc7baxY8eGakpLSzusuXr1anSzAgAAuElEgcfn8ykvL09Hjx5VdXW1WltblZWVpebm5k77FBUVye/3h7bz588rLi5Ozz33XFidy+UKq/P7/YqNjY1uVgAAADeJiaT4o48+Ctvfvn274uPjdeLECWVmZnbYx+12y+12h/b37Nmjixcv6vnnnw+rczgcSkxMjGQ4AAAA3XJH9/AEAgFJUlxcXLf7lJSUaPbs2UpJSQlrv3LlilJSUpSUlKSFCxeqvr6+y/O0tLQoGAyGbQAAAB2JOvAYY5Sfn6/p06dr3Lhx3erj9/u1f/9+rVixIqx99OjRKi0tVVVVlcrKyhQbG6tp06bp9OnTnZ6rsLAwdPXI7XYrOTk52qkAAADLOYwxJpqOeXl52rt3rw4fPqykpKRu9SksLNRbb72lb775RgMGDOi07vr165o4caIyMzNVXFzcYU1LS4taWlpC+8FgUMnJyQoEAnK5XJFNBgAA3BPBYFBut7vHn78juofnhtWrV6uqqkq1tbXdDjvGGL3//vvKycnpMuxIUr9+/TR58uQur/A4nU45nc6Ixg0AAB5MEb2kZYzRqlWrVF5eroMHD2rEiBHd7uvz+XTmzBktX768W7+noaFBHo8nkuEBAAB0KKIrPHl5edq5c6cqKys1aNAgNTU1SWp7J9bAgQMlSQUFBWpsbNSOHTvC+paUlGjKlCkd3u+zceNGpaena9SoUQoGgyouLlZDQ4O2bt0a7bwAAABCIgo827ZtkyQ99dRTYe3bt29Xbm6upLYbk8+dOxd2PBAIyOv1qqioqMPzXrp0SS+++KKamprkdrs1YcIE1dbW6oknnohkeAAAAB2K+qbl+01v3fQEAADunt56/ua7tAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgvYgCT2FhoSZPnqxBgwYpPj5eS5Ys0alTp7rsU1NTI4fD0W778ssvw+q8Xq/S0tLkdDqVlpamioqKyGcDAADQgYgCj8/nU15eno4eParq6mq1trYqKytLzc3Nt+176tQp+f3+0DZq1KjQsbq6OmVnZysnJ0cnT55UTk6Oli5dqmPHjkU+IwAAgFs4jDEm2s7ffvut4uPj5fP5lJmZ2WFNTU2NZs6cqYsXL+rhhx/usCY7O1vBYFD79+8Ptc2bN0+DBw9WWVlZt8YSDAbldrsVCATkcrkingsAAOh9vfX8fUf38AQCAUlSXFzcbWsnTJggj8ejWbNm6dChQ2HH6urqlJWVFdY2d+5cHTlypNPztbS0KBgMhm0AAAAdiTrwGGOUn5+v6dOna9y4cZ3WeTwevffee/J6vSovL1dqaqpmzZql2traUE1TU5MSEhLC+iUkJKipqanT8xYWFsrtdoe25OTkaKcCAAAsFxNtx1WrVumzzz7T4cOHu6xLTU1VampqaD8jI0Pnz5/Xm2++GfYymMPhCOtnjGnXdrOCggLl5+eH9oPBIKEHAAB0KKorPKtXr1ZVVZUOHTqkpKSkiPunp6fr9OnTof3ExMR2V3MuXLjQ7qrPzZxOp1wuV9gGAADQkYgCjzFGq1atUnl5uQ4ePKgRI0ZE9Uvr6+vl8XhC+xkZGaqurg6rOXDggKZOnRrV+QEAAG4W0UtaeXl52rlzpyorKzVo0KDQVRm3262BAwdKanupqbGxUTt27JAkbd68WY888ojGjh2ra9eu6de//rW8Xq+8Xm/ovGvXrlVmZqbeeOMNLV68WJWVlfrkk09u+3IZAABAd0QUeLZt2yZJeuqpp8Lat2/frtzcXEmS3+/XuXPnQseuXbumn//852psbNTAgQM1duxY7d27VwsWLAjVTJ06Vbt27dKGDRv0yiuvaOTIkdq9e7emTJkS5bQAAAD+4I4+h+d+wufwAADQ9/SJz+EBAADoCwg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALBeRIGnsLBQkydP1qBBgxQfH68lS5bo1KlTXfYpLy/XnDlzNHToULlcLmVkZOjjjz8OqyktLZXD4Wi3Xb16NfIZAQAA3CKiwOPz+ZSXl6ejR4+qurpara2tysrKUnNzc6d9amtrNWfOHO3bt08nTpzQzJkztWjRItXX14fVuVwu+f3+sC02Nja6WQEAANzEYYwx0Xb+9ttvFR8fL5/Pp8zMzG73Gzt2rLKzs/XLX/5SUtsVnpdeekmXLl3q9jlaWlrU0tIS2g8Gg0pOTlYgEJDL5er2eQAAwL0TDAbldrt7/Pn7ju7hCQQCkqS4uLhu97l+/bouX77crs+VK1eUkpKipKQkLVy4sN0VoFsVFhbK7XaHtuTk5MgnAAAAHghRX+Exxmjx4sW6ePGiPv300273+9WvfqVNmzbpiy++UHx8vCTp6NGjOnPmjP7kT/5EwWBQRUVF2rdvn06ePKlRo0Z1eB6u8AAA0Pf11hWeqANPXl6e9u7dq8OHDyspKalbfcrKyrRixQpVVlZq9uzZndZdv35dEydOVGZmpoqLi7t17t76HwYAAO6e3nr+jomm0+rVq1VVVaXa2tpuh53du3dr+fLl+uCDD7oMO5LUr18/TZ48WadPn45meAAAAGEiuofHGKNVq1apvLxcBw8e1IgRI7rVr6ysTLm5udq5c6eefvrpbv2ehoYGeTyeSIYHAADQoYiu8OTl5Wnnzp2qrKzUoEGD1NTUJElyu90aOHCgJKmgoECNjY3asWOHpLaw89Of/lRFRUVKT08P9Rk4cKDcbrckaePGjUpPT9eoUaMUDAZVXFyshoYGbd269a5NFAAAPLgiusKzbds2BQIBPfXUU/J4PKFt9+7doRq/369z586F9t999121trYqLy8vrM/atWtDNZcuXdKLL76oMWPGKCsrS42NjaqtrdUTTzxxF6YIAAAedHf0OTz3E25aBgCg7+kTn8MDAADQFxB4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrxdzrAQBAV374Qfr0U8nvlzweacYM6aGH7vWoAPQ19l3haWpq3+b3S6+91vbfjtzuOIB7orxceuQRaeZM6c//vO2/jzzS1g4AkYgo8BQWFmry5MkaNGiQ4uPjtWTJEp06deq2/Xw+nx5//HHFxsbq0Ucf1TvvvNOuxuv1Ki0tTU6nU2lpaaqoqIhkaH/QWeDZuLHrwNPVcQC9rrxc+tM/lf77v8PbGxvb2gk9ACIRUeDx+XzKy8vT0aNHVV1drdbWVmVlZam5ubnTPmfPntWCBQs0Y8YM1dfXa/369VqzZo28Xm+opq6uTtnZ2crJydHJkyeVk5OjpUuX6tixY9HPDECf9cMP0tq1kjHtj91oe+mltjoA6A6HMR39ldI93377reLj4+Xz+ZSZmdlhzcsvv6yqqip98cUXobaVK1fq5MmTqqurkyRlZ2crGAxq//79oZp58+Zp8ODBKisr6/C8LS0tamlpCe0Hg0ElJycrUFws17Rp0rffth0YOlT6t3+TXnhB+sd/lCZObGvv10+6fr3t546OezxtG4BeV1PT9vLV7Rw6JD31VE+PBkBPCgaDcrvdCgQCcrlcPfZ77uim5UAgIEmKi4vrtKaurk5ZWVlhbXPnzlVJSYm+//579e/fX3V1dVq3bl27ms2bN3d63sLCQm3cuLH9gTVrOh/wCy/84ecnn5R8vs6Pv/pq2309AHpdd19d5lVoAN0VdeAxxig/P1/Tp0/XuHHjOq1rampSQkJCWFtCQoJaW1v13XffyePxdFrT1NH9OL9XUFCg/Pz80P6NKzwqLpbu1hUeAPdEd5cfyxRAd0UdeFatWqXPPvtMhw8fvm2tw+EI27/xKtrN7R3V3Np2M6fTKafT2f7A+PF/CC23mjix82PdOQ6gV8yYISUltd2g3NGL7g5H2/EZM3p/bAD6pqjelr569WpVVVXp0KFDSkpK6rI2MTGx3ZWaCxcuKCYmRkOGDOmy5tarPgAeDA89JBUVtf186797buxv3szn8QDovogCjzFGq1atUnl5uQ4ePKgRI0bctk9GRoaqq6vD2g4cOKBJkyapf//+XdZMnTo1kuG1SUxs3+bxtN2T09n179sdB9DrnnlG+vBD6f/9v/D2pKS29meeuTfjAtA3RfQurb/+67/Wzp07VVlZqdTU1FC72+3WwIEDJbXdW9PY2KgdO3ZIantb+rhx4/Szn/1ML7zwgurq6rRy5UqVlZXp2WeflSQdOXJEmZmZev3117V48WJVVlZqw4YNOnz4sKZMmdKtsfXWXd4AeheftAzYrbeevyMKPJ3dU7N9+3bl5uZKknJzc/X111+rpqYmdNzn82ndunX6/PPPNWzYML388stauXJl2Dk+/PBDbdiwQV999ZVGjhyp119/Xc9E8E84Ag8AAH3PfRl47mcEHgAA+p7eev6277u0AAAAbkHgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrRRx4amtrtWjRIg0bNkwOh0N79uzpsj43N1cOh6PdNnbs2FBNaWlphzVXr16NeEIAAAC3ijjwNDc3a/z48dqyZUu36ouKiuT3+0Pb+fPnFRcXp+eeey6szuVyhdX5/X7FxsZGOjwAAIB2YiLtMH/+fM2fP7/b9W63W263O7S/Z88eXbx4Uc8//3xYncPhUGJiYqTDAQAAuK1ev4enpKREs2fPVkpKSlj7lStXlJKSoqSkJC1cuFD19fVdnqelpUXBYDBsAwAA6EivBh6/36/9+/drxYoVYe2jR49WaWmpqqqqVFZWptjYWE2bNk2nT5/u9FyFhYWhq0dut1vJyck9PXwAANBHOYwxJurODocqKiq0ZMmSbtUXFhbqrbfe0jfffKMBAwZ0Wnf9+nVNnDhRmZmZKi4u7rCmpaVFLS0tof1gMKjk5GQFAgG5XK6I5gEAAO6NYDAot9vd48/fEd/DEy1jjN5//33l5OR0GXYkqV+/fpo8eXKXV3icTqecTufdHiYAALBQr72k5fP5dObMGS1fvvy2tcYYNTQ0yOPx9MLIAACA7SK+wnPlyhWdOXMmtH/27Fk1NDQoLi5Ow4cPV0FBgRobG7Vjx46wfiUlJZoyZYrGjRvX7pwbN25Uenq6Ro0apWAwqOLiYjU0NGjr1q1RTAkAACBcxIHn+PHjmjlzZmg/Pz9fkrRs2TKVlpbK7/fr3LlzYX0CgYC8Xq+Kioo6POelS5f04osvqqmpSW63WxMmTFBtba2eeOKJSIcHAADQzh3dtHw/6a2bngAAwN3TW8/ffJcWAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKwXceCpra3VokWLNGzYMDkcDu3Zs6fL+pqaGjkcjnbbl19+GVbn9XqVlpYmp9OptLQ0VVRURDo0AACADkUceJqbmzV+/Hht2bIlon6nTp2S3+8PbaNGjQodq6urU3Z2tnJycnTy5Enl5ORo6dKlOnbsWKTDAwAAaMdhjDFRd3Y4VFFRoSVLlnRaU1NTo5kzZ+rixYt6+OGHO6zJzs5WMBjU/v37Q23z5s3T4MGDVVZW1q2xBINBud1uBQIBuVyuSKYBAADukd56/u61e3gmTJggj8ejWbNm6dChQ2HH6urqlJWVFdY2d+5cHTlypNPztbS0KBgMhm0AAAAd6fHA4/F49N5778nr9aq8vFypqamaNWuWamtrQzVNTU1KSEgI65eQkKCmpqZOz1tYWCi32x3akpOTe2wOAACgb4vp6V+Qmpqq1NTU0H5GRobOnz+vN998U5mZmaF2h8MR1s8Y067tZgUFBcrPzw/tB4NBQg8AAOjQPXlbenp6uk6fPh3aT0xMbHc158KFC+2u+tzM6XTK5XKFbQAAAB25J4Gnvr5eHo8ntJ+RkaHq6uqwmgMHDmjq1Km9PTQAAGChiF/SunLlis6cORPaP3v2rBoaGhQXF6fhw4eroKBAjY2N2rFjhyRp8+bNeuSRRzR27Fhdu3ZNv/71r+X1euX1ekPnWLt2rTIzM/XGG29o8eLFqqys1CeffKLDhw/fhSkCAIAHXcSB5/jx45o5c2Zo/8Z9NMuWLVNpaan8fr/OnTsXOn7t2jX9/Oc/V2NjowYOHKixY8dq7969WrBgQahm6tSp2rVrlzZs2KBXXnlFI0eO1O7duzVlypQ7mRsAAICkO/wcnvsJn8MDAEDfY93n8AAAANwrBB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsF7Egae2tlaLFi3SsGHD5HA4tGfPni7ry8vLNWfOHA0dOlQul0sZGRn6+OOPw2pKS0vlcDjabVevXo10eAAAAO1EHHiam5s1fvx4bdmypVv1tbW1mjNnjvbt26cTJ05o5syZWrRokerr68PqXC6X/H5/2BYbGxvp8AAAANqJibTD/PnzNX/+/G7Xb968OWz/7/7u71RZWal/+Zd/0YQJE0LtDodDiYmJkQ4HAADgtnr9Hp7r16/r8uXLiouLC2u/cuWKUlJSlJSUpIULF7a7AnSrlpYWBYPBsA0AAKAjvR543nrrLTU3N2vp0qWhttGjR6u0tFRVVVUqKytTbGyspk2bptOnT3d6nsLCQrnd7tCWnJzcG8MHAAB9kMMYY6Lu7HCooqJCS5Ys6VZ9WVmZVqxYocrKSs2ePbvTuuvXr2vixInKzMxUcXFxhzUtLS1qaWkJ7QeDQSUnJysQCMjlckU0DwAAcG8Eg0G53e4ef/6O+B6eaO3evVvLly/XBx980GXYkaR+/fpp8uTJXV7hcTqdcjqdd3uYAADAQr3yklZZWZlyc3O1c+dOPf3007etN8aooaFBHo+nF0YHAABsF/EVnitXrujMmTOh/bNnz6qhoUFxcXEaPny4CgoK1NjYqB07dkhqCzs//elPVVRUpPT0dDU1NUmSBg4cKLfbLUnauHGj0tPTNWrUKAWDQRUXF6uhoUFbt269G3MEAAAPuIiv8Bw/flwTJkwIvaU8Pz9fEyZM0C9/+UtJkt/v17lz50L17777rlpbW5WXlyePxxPa1q5dG6q5dOmSXnzxRY0ZM0ZZWVlqbGxUbW2tnnjiiTudHwAAwJ3dtHw/6a2bngAAwN3TW8/ffJcWAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANYj8AAAAOsReAAAgPUIPAAAwHoEHgAAYD0CDwAAsB6BBwAAWI/AAwAArEfgAQAA1iPwAAAA6xF4AACA9Qg8AADAegQeAABgPQIPAACwHoEHAABYj8ADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFgv5l4P4G779FNp3jzpoYfa9n/4oa3N75c8HmnGjD8cu93x2/UF0PPuZI2yhgGEGEsEAgEjyUgBk5RkjNfbtiUlGSP9YbtxzJiuj9+urzHGmG++MebVV9v+C+Cuu5M1esdr+Hbru6f6Ag+YG8/fgUCgR39PxIHH5/OZhQsXGo/HYySZioqK2/apqakxEydONE6n04wYMcJs27atXc2HH35oxowZYwYMGGDGjBljysvLIxrXzYHH4Qj/S+7mzeFo2/7mb0yHdd3pG/oL88SJtgMnTkQ0VgC35/VGv0a7Wt/dXsO3W9891Rd4wPRW4In4Hp7m5maNHz9eW7Zs6Vb92bNntWDBAs2YMUP19fVav3691qxZI6/XG6qpq6tTdna2cnJydPLkSeXk5Gjp0qU6duxYpMOT1PZXW1fHjJHefrvjutv1laSXXmq7VA6gZ/zwg7R2bXRrtDvrmzUMPHgivodn/vz5mj9/frfr33nnHQ0fPlybN2+WJI0ZM0bHjx/Xm2++qWeffVaStHnzZs2ZM0cFBQWSpIKCAvl8Pm3evFllZWUdnrelpUUtLS2h/UAg8Pufgt0aV7R/2Q01TRp8vkmfbpEm9jvZ1vib30hXrrT9nJjYtgGI2qefSv/939H372p9d7mGv/uubf+P/1g62cH67tdPun697edbj99JX4m/O/DACgbbnrdNV/+auRvu5PKQuvGS1owZM8yaNWvC2srLy01MTIy5du2aMcaY5ORk8/bbb4fVvP3222b48OGdnvfVV1/9/UtYbGxsbGxsbH19+93vfhddGOmmHn+XVlNTkxISEsLaEhIS1Nraqu+++04ej6fTmqampk7PW1BQoPz8/ND+pUuXlJKSonPnzsntdt/dSdzHgsGgkpOTdf78eblcrns9nF7DvJn3g4B5M+8HQSAQ0PDhwxUXF9ejv6dX3pbucDjC9s3vL1vd3N5Rza1tN3M6nXI6ne3a3W73A/UH5QaXy8W8HyDM+8HCvB8sD+q8+/Xr2Y8G7PEPHkxMTGx3pebChQuKiYnRkCFDuqy59aoPAABANHo88GRkZKi6ujqs7cCBA5o0aZL69+/fZc3UqVN7engAAOABEPFLWleuXNGZM2dC+2fPnlVDQ4Pi4uI0fPhwFRQUqLGxUTt27JAkrVy5Ulu2bFF+fr5eeOEF1dXVqaSkJOzdV2vXrlVmZqbeeOMNLV68WJWVlfrkk090+PDhbo/L6XTq1Vdf7fBlLpsxb+b9IGDezPtBwLx7dt4OYyJ7H1hNTY1mzpzZrn3ZsmUqLS1Vbm6uvv76a9XU1ISO+Xw+rVu3Tp9//rmGDRuml19+WStXrgzr/+GHH2rDhg366quvNHLkSL3++ut65plnopsVAADATSIOPAAAAH0N35YOAACsR+ABAADWI/AAAADrEXgAAID17svAU1tbq0WLFmnYsGFyOBzas2fPbfv4fD49/vjjio2N1aOPPqp33nmnXY3X61VaWpqcTqfS0tJUUVHRA6OPXqTzLi8v15w5czR06FC5XC5lZGTo448/DqspLS2Vw+Fot129erUHZxKZSOddU1PT4Zy+/PLLsDrbHu/c3NwO5z127NhQzf3+eBcWFmry5MkaNGiQ4uPjtWTJEp06deq2/fr6+o5m3jas72jmbcP6jmbeNqzvbdu26bHHHgt9UnRGRob279/fZZ/eXNv3ZeBpbm7W+PHjtWXLlm7Vnz17VgsWLNCMGTNUX1+v9evXa82aNfJ6vaGauro6ZWdnKycnRydPnlROTo6WLl2qY8eO9dQ0IhbpvGtrazVnzhzt27dPJ06c0MyZM7Vo0SLV19eH1blcLvn9/rAtNja2J6YQlUjnfcOpU6fC5jRq1KjQMRsf76KiorD5nj9/XnFxcXruuefC6u7nx9vn8ykvL09Hjx5VdXW1WltblZWVpebm5k772LC+o5m3Des7mnnf0JfXdzTztmF9JyUladOmTTp+/LiOHz+un/zkJ1q8eLE+//zzDut7fW336FeT3gXS7b+R/W//9m/N6NGjw9p+9rOfmfT09ND+0qVLzbx588Jq5s6da/7sz/7sro31burOvDuSlpZmNm7cGNrfvn27cbvdd29gPaw78z506JCRZC5evNhpzYPweFdUVBiHw2G+/vrrUFtfe7wvXLhgJBmfz9dpjY3ruzvz7khfX9/dmbeN6zuax9uG9W2MMYMHDzb/9E//1OGx3l7b9+UVnkjV1dUpKysrrG3u3Lk6fvy4vv/++y5rjhw50mvj7GnXr1/X5cuX233j7JUrV5SSkqKkpCQtXLiw3b8Q+6oJEybI4/Fo1qxZOnToUNixB+HxLikp0ezZs5WSkhLW3pce70AgIEldfkuyjeu7O/O+lQ3rO5J527S+o3m8+/r6/uGHH7Rr1y41NzcrIyOjw5reXttWBJ6mpqZ2XzSakJCg1tZWfffdd13W3PqlpX3ZW2+9pebmZi1dujTUNnr0aJWWlqqqqkplZWWKjY3VtGnTdPr06Xs40jvj8Xj03nvvyev1qry8XKmpqZo1a5Zqa2tDNbY/3n6/X/v379eKFSvC2vvS422MUX5+vqZPn65x48Z1Wmfb+u7uvG/V19d3d+dt2/qO5vHuy+v7t7/9rX70ox/J6XRq5cqVqqioUFpaWoe1vb22I/4urfuVw+EI2ze//wDpm9s7qrm1ra8qKyvTa6+9psrKSsXHx4fa09PTlZ6eHtqfNm2aJk6cqH/4h39QcXHxvRjqHUtNTVVqampoPyMjQ+fPn9ebb76pzMzMULvNj3dpaakefvhhLVmyJKy9Lz3eq1at0meffdat78yzaX1HMu8bbFjf3Z23bes7mse7L6/v1NRUNTQ06NKlS/J6vVq2bJl8Pl+noac317YVV3gSExPbpb0LFy4oJiZGQ4YM6bLm1uTYF+3evVvLly/XP//zP2v27Nld1vbr10+TJ0++r/5FcDekp6eHzcnmx9sYo/fff185OTkaMGBAl7X36+O9evVqVVVV6dChQ0pKSuqy1qb1Hcm8b7BhfUcz75v11fUdzbz7+voeMGCAfvzjH2vSpEkqLCzU+PHjVVRU1GFtb69tKwJPRkaGqqurw9oOHDigSZMmqX///l3WTJ06tdfG2RPKysqUm5urnTt36umnn75tvTFGDQ0N8ng8vTC63lNfXx82J1sfb6ntHSBnzpzR8uXLb1t7vz3exhitWrVK5eXlOnjwoEaMGHHbPjas72jmLfX99R3tvG/V19b3ncy7L6/vjhhj1NLS0uGxXl/bEd/m3AsuX75s6uvrTX19vZFk3n77bVNfX2/+67/+yxhjzC9+8QuTk5MTqv/qq6/MH/3RH5l169aZ//iP/zAlJSWmf//+5sMPPwzV/OY3vzEPPfSQ2bRpk/niiy/Mpk2bTExMjDl69Givz68zkc57586dJiYmxmzdutX4/f7QdunSpVDNa6+9Zj766CPzu9/9ztTX15vnn3/exMTEmGPHjvX6/DoT6bz//u//3lRUVJj//M//NP/+7/9ufvGLXxhJxuv1hmpsfLxv+Iu/+AszZcqUDs95vz/ef/VXf2XcbrepqakJ+zP7f//3f6EaG9d3NPO2YX1HM28b1nc0876hL6/vgoICU1tba86ePWs+++wzs379etOvXz9z4MABY8y9X9v3ZeC58bbEW7dly5YZY4xZtmyZefLJJ8P61NTUmAkTJpgBAwaYRx55xGzbtq3deT/44AOTmppq+vfvb0aPHh22gO4Hkc77ySef7LLeGGNeeuklM3z4cDNgwAAzdOhQk5WVZY4cOdK7E7uNSOf9xhtvmJEjR5rY2FgzePBgM336dLN3795257Xt8TbGmEuXLpmBAwea9957r8Nz3u+Pd0fzlWS2b98eqrFxfUczbxvWdzTztmF9R/vnvK+v77/8y780KSkpofHNmjUrFHaMufdr22HM7+8QAgAAsJQV9/AAAAB0hcADAACsR+ABAADWI/AAAADrEXgAAID1CDwAAMB6BB4AAGA9Ag8AALAegQcAAFiPwAMAAKxH4AEAANb7/zpvZj2X9GdlAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Victoria\n",
    "Created on 2017.9.19 21:00\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "class SOMNet():\n",
    "    def __init__(self, input_dims, output_nums, sigma0, rta0, tau1, tau2, iterations):\n",
    "        self.input_dims = input_dims\n",
    "        self.output_nums = output_nums\n",
    "        self.sigma0 = sigma0\n",
    "        self.eta0 = eta0\n",
    "        self.tau1 = tau1        \n",
    "        self.tau2 = tau2\n",
    "        self.iterations = iterations\n",
    "        self.weights = np.random.rand(output_nums, input_dims)\n",
    "\n",
    "    def distance(self, w, x):\n",
    "        \"\"\"\n",
    "        Compute distance between array w and vector v2.\n",
    "        Input:\n",
    "            w: np.array with shape [m, d]\n",
    "            x: np.array with shape [1, d]\n",
    "        Return:\n",
    "            dist_square: np.array with shape [m, 1] when w is array or float when w is vector\n",
    "        \"\"\"\n",
    "        m = w.shape[0]\n",
    "        if m==1:\n",
    "            dist_square = np.sum((w-x)**2)\n",
    "        else:\n",
    "            dist_square = np.sum((w-x)**2, axis=1, keepdims=True)\n",
    "        return dist_square\n",
    "\n",
    "    def bmu(self, x):\n",
    "        \"\"\"\n",
    "        Compute the best match unit(BMU) given input vector x.\n",
    "        Input:\n",
    "            x: np.array with shape [1, d].\n",
    "        Return:\n",
    "            index: the index of BMU\n",
    "        \"\"\"\n",
    "        dist_square = self.distance(self.weights, x)\n",
    "        index = np.argmax(dist_square)\n",
    "        return index\n",
    "\n",
    "    def radius(self, iter):\n",
    "        \"\"\"\n",
    "        Computer neighborhood radius for current BMU.\n",
    "        Input:\n",
    "            iter: the current iteration.\n",
    "        \"\"\"\n",
    "        sigma = self.sigma0 * np.exp(-iter / self.tau1)\n",
    "        return sigma\n",
    "\n",
    "    def update(self, x, iter, sigma):\n",
    "        \"\"\"\n",
    "        Update weight vector for all output unit each iteration.\n",
    "        Input:\n",
    "            x: np.array with shape [1, d]. The current input vector.\n",
    "            iter: int, the current iteration.\n",
    "            sigma: float, the current neighborhood function.\n",
    "        \"\"\"\n",
    "        eta = self.eta0 * np.exp(-iter / self.tau2)\n",
    "        neighbor_function = np.exp( - self.distance(self.weights, x) / (2*sigma*sigma) ) \n",
    "        self.weights = self.weights + eta * neighbor_function * (x - self.weights)\n",
    "\n",
    "    def train(self, train_X):\n",
    "        \"\"\"\n",
    "        Learning the weight vectors of all output units.\n",
    "        Input:\n",
    "            train_X: list with lenght n and element is np.array with shape [1, d]. Training instances.       \n",
    "        \"\"\"\n",
    "        n = len(train_X)\n",
    "        for iter in range(self.iterations):\n",
    "            #step 2: choose instance from train set randomly\n",
    "            x = train_X[random.randint(0, n-1)]\n",
    "\n",
    "            #step 3: compute BMU for current instance\n",
    "            bmu = self.bmu(x)\n",
    "\n",
    "            #step 4: computer neighborhood radius\n",
    "            sigma = self.radius(iter)\n",
    "\n",
    "            #step5: update weight vectors for all output unit\n",
    "            self.update(x, iter, sigma)\n",
    "        print(sigma)\n",
    "\n",
    "    def eval(self, x):\n",
    "        \"\"\"\n",
    "        Computer index of BMU given input vector.\n",
    "        \"\"\"\n",
    "        return self.bmu(x)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    #prepare train data\n",
    "    train_X = datas\n",
    "    train_y = labs\n",
    "    #training SOM network\n",
    "    output_nums = 4\n",
    "    sigma0 = 3\n",
    "    eta0 = 0.1\n",
    "    tau1 = 1\n",
    "    tau2 = 1\n",
    "    iterations = 100                         \n",
    "    som_net = SOMNet(2, output_nums, sigma0, eta0, tau1, tau2, iterations)\n",
    "    som_net.train(train_X)\n",
    "\n",
    "    #plot data in 2 dimension space\n",
    "    left_top_count = 0\n",
    "    left_bottom_count = 0\n",
    "    right_top_count = 0\n",
    "    right_bottom_count = 0\n",
    "    for i in range(len(train_X)):\n",
    "        bmu = som_net.eval(train_X[i])\n",
    "        if train_y[i] == 1:\n",
    "            style = \"bo\"\n",
    "        else:\n",
    "            style = \"r+\"\n",
    "        print(bmu)\n",
    "        if bmu == 0:\n",
    "            plt.plot([1+left_top_count*0.03], [2], style)\n",
    "            left_top_count += 1\n",
    "        elif bmu == 1:\n",
    "            plt.plot([2+right_top_count*0.03], [2], style)\n",
    "            right_top_count += 1            \n",
    "        elif bmu == 2:\n",
    "            plt.plot([1+left_bottom_count*0.03], [1], style)\n",
    "            left_bottom_count += 1           \n",
    "        else:\n",
    "            plt.plot([2+right_bottom_count*0.03], [1], style)\n",
    "            right_bottom_count += 1\n",
    "\n",
    "    plt.xlim([1, 3])\n",
    "    plt.ylim([1, 3])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n",
      "epoch: 0, iter:50, loss: 1.352\n",
      "epoch: 0, iter:100, loss: 0.6122\n",
      "epoch: 0, iter:150, loss: 0.2786\n",
      "epoch: 0, iter:200, loss: 0.171\n",
      "epoch: 0, iter:250, loss: 0.1355\n",
      "epoch: 0, iter:300, loss: 0.07819\n",
      "epoch: 0, iter:350, loss: 0.1685\n",
      "epoch: 0, iter:400, loss: 0.2389\n",
      "epoch: 0, iter:450, loss: 0.12\n",
      "epoch: 0, iter:500, loss: 0.1156\n",
      "epoch: 0, iter:550, loss: 0.2204\n",
      "epoch: 0, iter:600, loss: 0.06053\n",
      "epoch: 0, iter:650, loss: 0.05902\n",
      "epoch: 0, iter:700, loss: 0.05292\n",
      "epoch: 0, iter:750, loss: 0.1626\n",
      "epoch: 0, iter:800, loss: 0.03293\n",
      "epoch: 0, iter:850, loss: 0.01562\n",
      "epoch: 0, iter:900, loss: 0.1228\n",
      "epoch: 1, iter:950, loss: 0.1266\n",
      "epoch: 1, iter:1000, loss: 0.0984\n",
      "epoch: 1, iter:1050, loss: 0.06906\n",
      "epoch: 1, iter:1100, loss: 0.05163\n",
      "epoch: 1, iter:1150, loss: 0.03628\n",
      "epoch: 1, iter:1200, loss: 0.01078\n",
      "epoch: 1, iter:1250, loss: 0.01973\n",
      "epoch: 1, iter:1300, loss: 0.06717\n",
      "epoch: 1, iter:1350, loss: 0.04497\n",
      "epoch: 1, iter:1400, loss: 0.04103\n",
      "epoch: 1, iter:1450, loss: 0.05704\n",
      "epoch: 1, iter:1500, loss: 0.04332\n",
      "epoch: 1, iter:1550, loss: 0.007955\n",
      "epoch: 1, iter:1600, loss: 0.1445\n",
      "epoch: 1, iter:1650, loss: 0.05489\n",
      "epoch: 1, iter:1700, loss: 0.03996\n",
      "epoch: 1, iter:1750, loss: 0.03861\n",
      "epoch: 1, iter:1800, loss: 0.05209\n",
      "epoch: 1, iter:1850, loss: 0.04348\n",
      "epoch: 2, iter:1900, loss: 0.01235\n",
      "epoch: 2, iter:1950, loss: 0.03732\n",
      "epoch: 2, iter:2000, loss: 0.05203\n",
      "epoch: 2, iter:2050, loss: 0.1083\n",
      "epoch: 2, iter:2100, loss: 0.032\n",
      "epoch: 2, iter:2150, loss: 0.1427\n",
      "epoch: 2, iter:2200, loss: 0.02115\n",
      "epoch: 2, iter:2250, loss: 0.03635\n",
      "epoch: 2, iter:2300, loss: 0.02282\n",
      "epoch: 2, iter:2350, loss: 0.1034\n",
      "epoch: 2, iter:2400, loss: 0.05834\n",
      "epoch: 2, iter:2450, loss: 0.102\n",
      "epoch: 2, iter:2500, loss: 0.07742\n",
      "epoch: 2, iter:2550, loss: 0.06888\n",
      "epoch: 2, iter:2600, loss: 0.0297\n",
      "epoch: 2, iter:2650, loss: 0.007528\n",
      "epoch: 2, iter:2700, loss: 0.07411\n",
      "epoch: 2, iter:2750, loss: 0.1156\n",
      "epoch: 2, iter:2800, loss: 0.04424\n",
      "Start eval!\n",
      "Test Loss: 0.054962, Acc: 0.982700\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    " \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 25 × 26 × 26\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # 输入通道为1，输出通道为25，卷积核大小为3\n",
    "            nn.Conv2d(1, 25, kernel_size=3),\n",
    "            # 二维批量归一化\n",
    "            nn.BatchNorm2d(25),\n",
    "            # 引入非线性\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        #25 × 13 × 13\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    " \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(25, 50, kernel_size=3),\n",
    "            nn.BatchNorm2d(50),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    " \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    " \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(50 * 5 * 5, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#-------------------------------------超参数定义-------------------------------------\n",
    "batch_size = 64 #一个batch的size\n",
    "learning_rate = 0.02\n",
    "num_epoches = 3 #总样本的迭代次数\n",
    "\n",
    "#-------------------------------------数据预处理方法--------------------------------------\n",
    "# transforms.ToTensor()将图片转换成PyTorch中处理的对象Tensor,并且进行标准化（数据在0~1之间）\n",
    "# transforms.Normalize()做归一化。它进行了减均值，再除以标准差。两个参数分别是均值和标准差\n",
    "# transforms.Compose()函数则是将各种预处理的操作组合到了一起\n",
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "#-------------------------------------数据集的下载器--------------------------------------\n",
    "#训练和测试集预处理\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_tf, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_tf)\n",
    "#加载数据集\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#-------------------------------------选择模型--------------------------------------\n",
    "'''\n",
    "1. 输入28*28(因为输入的图像像素为28*28)\n",
    "2. 隐藏层分别为300和100\n",
    "3. 输出层为10，因为识别的数字为0~9\n",
    "'''\n",
    "#下列3个模型可以任选其中之一\n",
    "model = CNN() \n",
    "# model = net.Activation_Net(28 * 28, 300, 100, 10)\n",
    "# model = net.Batch_Net(28 * 28, 300, 100, 10)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "#-------------------------------------定义损失函数和优化器--------------------------------------\n",
    "#交叉熵和SGD优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#-------------------------------------开始训练-------------------------------------\n",
    "print('Start Training!')\n",
    "iter = 0 #迭代次数\n",
    "for epoch in range(num_epoches):\n",
    "    for data in train_loader:\n",
    "        img, label = data\n",
    "        #img = img.view(img.size(0), -1)\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        else:\n",
    "            img = img\n",
    "            label = label\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter+=1\n",
    "        #每迭代50次打印一次\n",
    "        if iter%50 == 0:\n",
    "            print('epoch: {}, iter:{}, loss: {:.4}'.format(epoch, iter, loss.data.item()))\n",
    "\n",
    "#-------------------------------------模型评估-------------------------------------\n",
    "print('Start eval!')\n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "eval_acc = 0\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    #img = img.view(img.size(0), -1)\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "    out = model(img)\n",
    "    loss = criterion(out, label)\n",
    "    eval_loss += loss.data.item()*label.size(0)\n",
    "    _, pred = torch.max(out, 1)\n",
    "    num_correct = (pred == label).sum()\n",
    "    eval_acc += num_correct.item()\n",
    "\n",
    "print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(test_dataset)), eval_acc / (len(test_dataset))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
