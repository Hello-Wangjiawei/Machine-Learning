{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "# 特征字典，后面用到了好多次，干脆当全局变量了\n",
    "featureDic = {\n",
    "    '色泽': ['浅白', '青绿', '乌黑'],\n",
    "    '根蒂': ['硬挺', '蜷缩', '稍蜷'],\n",
    "    '敲声': ['沉闷', '浊响', '清脆'],\n",
    "    '纹理': ['清晰', '模糊', '稍糊'],\n",
    "    '脐部': ['凹陷', '平坦', '稍凹'],\n",
    "    '触感': ['硬滑', '软粘']}\n",
    "\n",
    "\n",
    "def getDataSet():\n",
    "    \"\"\"\n",
    "    get watermelon data set 3.0 alpha.\n",
    "    :return: 编码好的数据集以及特征的字典。\n",
    "    \"\"\"\n",
    "    dataSet = [\n",
    "        ['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.697, 0.460, 1],\n",
    "        ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 0.774, 0.376, 1],\n",
    "        ['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.634, 0.264, 1],\n",
    "        ['青绿', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', 0.608, 0.318, 1],\n",
    "        ['浅白', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', 0.556, 0.215, 1],\n",
    "        ['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0.403, 0.237, 1],\n",
    "        ['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', 0.481, 0.149, 1],\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '硬滑', 0.437, 0.211, 1],\n",
    "        ['乌黑', '稍蜷', '沉闷', '稍糊', '稍凹', '硬滑', 0.666, 0.091, 0],\n",
    "        ['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', 0.243, 0.267, 0],\n",
    "        ['浅白', '硬挺', '清脆', '模糊', '平坦', '硬滑', 0.245, 0.057, 0],\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '软粘', 0.343, 0.099, 0],\n",
    "        ['青绿', '稍蜷', '浊响', '稍糊', '凹陷', '硬滑', 0.639, 0.161, 0],\n",
    "        ['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', 0.657, 0.198, 0],\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', 0.360, 0.370, 0],\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', 0.593, 0.042, 0],\n",
    "        ['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', 0.719, 0.103, 0]\n",
    "    ]\n",
    "\n",
    "    features = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '密度', '含糖量']\n",
    "    # features = ['color', 'root', 'knocks', 'texture', 'navel', 'touch', 'density', 'sugar']\n",
    "\n",
    "    # #得到特征值字典，本来用这个生成的特征字典，还是直接当全局变量方便\n",
    "    # featureDic = {}\n",
    "    # for i in range(len(features)):\n",
    "    #     featureList = [example[i] for example in dataSet]\n",
    "    #     uniqueFeature = list(set(featureList))\n",
    "    #     featureDic[features[i]] = uniqueFeature\n",
    "\n",
    "    # 每种特征的属性个数\n",
    "    numList = []  # [3, 3, 3, 3, 3, 2]\n",
    "    for i in range(len(features) - 2):\n",
    "        numList.append(len(featureDic[features[i]]))\n",
    "\n",
    "    dataSet = np.array(dataSet)\n",
    "    return dataSet[:, :-1], dataSet[:, -1], features\n",
    "\n",
    "\n",
    "# data, classLabel, feature = getDataSet()\n",
    "# print(data)\n",
    "# print(classLabel)\n",
    "# print(feature)\n",
    "\n",
    "\n",
    "def newData():\n",
    "    \"\"\"\n",
    "    利用pandas将分类变量转化为数值变量。将分类变量进行one-hot编码。\n",
    "    :return: 变量全为数值的变量，以及新的特征标签。\n",
    "    \"\"\"\n",
    "    dataSet, classLabel, features = getDataSet()\n",
    "    df = pd.DataFrame(dataSet)\n",
    "    df.columns = features\n",
    "    # 类别变量转化为数字变量\n",
    "    # features = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '密度', '含糖量']\n",
    "    # features = ['color', 'root', 'knocks', 'texture', 'navel', 'touch', 'density', 'sugar']\n",
    "    # 色泽\n",
    "    color = pd.get_dummies(df.色泽, prefix=\"色泽\")\n",
    "    # 根蒂\n",
    "    root = pd.get_dummies(df.根蒂, prefix=\"根蒂\")\n",
    "    # 敲声\n",
    "    knocks = pd.get_dummies(df.敲声, prefix=\"敲声\")\n",
    "    # 纹理\n",
    "    texture = pd.get_dummies(df.纹理, prefix=\"纹理\")\n",
    "    # 脐部\n",
    "    navel = pd.get_dummies(df.脐部, prefix=\"脐部\")\n",
    "    # 触感\n",
    "    touch = pd.get_dummies(df.触感, prefix=\"触感\")\n",
    "    # 密度和含糖量\n",
    "    densityAndsugar = pd.DataFrame()\n",
    "    densityAndsugar[\"密度\"] = df.密度\n",
    "    densityAndsugar[\"含糖量\"] = df.含糖量\n",
    "    # 融合\n",
    "    newData = pd.concat([color, root, knocks, texture, navel, touch, densityAndsugar], axis=1)\n",
    "    # print(\"newData\", newData)\n",
    "    newFeatures = list(newData.columns)\n",
    "    newData = np.asarray(newData, dtype=\"float64\")\n",
    "    classLabel = np.asarray(classLabel, dtype=\"int\").reshape(-1, 1)\n",
    "\n",
    "    # 新的特征数据和类融合\n",
    "    newDataSet = np.concatenate((newData, classLabel), axis=1)\n",
    "    # # 在第一列添加1\n",
    "    # newDataSet = np.insert(newDataSet, 0,\n",
    "    #                        np.ones(dataSet.shape[0]),\n",
    "    #                        axis=1)\n",
    "\n",
    "    return newDataSet, newFeatures\n",
    "\n",
    "\n",
    "# Sigmoid 函数\n",
    "def sigmoid(Z):\n",
    "    return 1.0 / (1 + np.exp(-Z))\n",
    "\n",
    "\n",
    "# 神经网络累计BP\n",
    "def NNetworkBP(dataSet, eta, thresh):\n",
    "    \"\"\"\n",
    "    :param dataSet: 数据集. m x n\n",
    "    :param eta: 学习率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    errHistory = []     # 记录每轮迭代的均方误差\n",
    "    y = dataSet[:, -1].reshape(-1, 1)\n",
    "    x = dataSet[:, :-1]\n",
    "    m, n = x.shape\n",
    "    # 隐层参数\n",
    "    v = np.random.randn(n, n + 1)\n",
    "    # 输出层参数\n",
    "    w = np.random.randn(n + 1, 1)\n",
    "    # 隐层阈值\n",
    "    gamma = np.random.randn(1, n + 1)\n",
    "    # 输出值\n",
    "    theta = np.random.random(1)\n",
    "\n",
    "    err = errOfMeanSqur(dataSet, v, gamma, w, theta)\n",
    "    while err > thresh:\n",
    "        b = sigmoid(np.dot(x, v) - gamma)  # m x (n+1)\n",
    "        beta = np.dot(b, w)     # m x 1\n",
    "        # 预测值\n",
    "        yHat = sigmoid(beta - theta)    # m x 1\n",
    "        # 输出层神经元梯度项\n",
    "        g = yHat * (1 - yHat) * (y - yHat)  # m x 1\n",
    "        # 隐层神经元梯度向\n",
    "        e = b * (1 - b) * np.dot(g, w.T)    # m x (n+1)\n",
    "        # 更新w, v, theta, gamma\n",
    "        w += eta * np.dot(b.T, g)\n",
    "        v += eta * np.dot(x.T, e)\n",
    "        theta -= eta * g.sum()\n",
    "        gamma -= eta * e.sum(axis=0)\n",
    "\n",
    "        err = errOfMeanSqur(dataSet, v, gamma, w, theta)\n",
    "        errHistory.append(err)\n",
    "\n",
    "    return v, gamma, w, theta, errHistory\n",
    "\n",
    "\n",
    "# 神经网络累计BP\n",
    "def NNetworkABP(dataSet, eta, thresh):\n",
    "    \"\"\"\n",
    "    :param dataSet: 数据集. m x n\n",
    "    :param eta: 学习率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    errHistory = []     # 记录每轮迭代的均方误差\n",
    "    y = dataSet[:, -1].reshape(-1, 1)\n",
    "    x = dataSet[:, :-1]\n",
    "    m, n = x.shape\n",
    "    # 隐层参数\n",
    "    v = np.random.randn(n, n + 1)\n",
    "    # 输出层参数\n",
    "    w = np.random.randn(n + 1, 1)\n",
    "    # 隐层阈值\n",
    "    gamma = np.random.randn(1, n + 1)\n",
    "    # 输出值\n",
    "    theta = np.random.random(1)\n",
    "\n",
    "    err = errOfMeanSqur(dataSet, v, gamma, w, theta)\n",
    "    while err > thresh:\n",
    "        for i in range(m):\n",
    "            b = sigmoid(np.dot(x[i], v) - gamma)  # 1 x (n+1)\n",
    "            beta = np.dot(b, w)[0]     # 1\n",
    "            # 预测值\n",
    "            yHat = sigmoid(beta - theta)  # 1\n",
    "            # 输出层神经元梯度项\n",
    "            g = yHat * (1 - yHat) * (y[i] - yHat)  # 1\n",
    "            print(\"g = \", g)\n",
    "            # 隐层神经元梯度向\n",
    "            e = b * (1 - b) * g * w.T.sum()   # 1 x (n+1)\n",
    "            # 更新w, v, theta, gamma\n",
    "            w += eta * b.T * g\n",
    "            v += eta * np.dot(x[i].reshape(n, -1), e)\n",
    "            theta -= eta * g\n",
    "            gamma -= eta * e\n",
    "\n",
    "            err = errOfMeanSqur(dataSet, v, gamma, w, theta)\n",
    "            errHistory.append(err)\n",
    "\n",
    "    return v, gamma, w, theta, errHistory\n",
    "\n",
    "\n",
    "def classify(data, v, gamma, w, theta):\n",
    "    b = sigmoid(np.dot(data, v) - gamma)\n",
    "    beta = np.dot(b, w)\n",
    "    yHat = sigmoid(beta - theta)\n",
    "    return yHat[0][0]\n",
    "\n",
    "\n",
    "def errOfMeanSqur(dataSet, v, gamma, w, theta):\n",
    "    x = dataSet[:, :-1]\n",
    "    y = dataSet[:, -1]\n",
    "    num = x.shape[0]\n",
    "    err = 0.0\n",
    "    for i in range(num):\n",
    "        yPre = classify(dataSet[i][:-1], v, gamma, w, theta)\n",
    "        err += ((y[i] - yPre) ** 2) / 2.0\n",
    "\n",
    "    return err / float(num)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # # test NNetwork\n",
    "    dataSet, _ = newData()\n",
    "    print(dataSet)\n",
    "    v1, gamma1, w1, theta1, errHistory1 = NNetworkBP(dataSet, 0.1, 0.001)\n",
    "    # 画图\n",
    "    plt.plot(np.arange(len(errHistory1)), errHistory1)\n",
    "    plt.show()\n",
    "    # test NNetworkABP(dataSet, eta, thresh)\n",
    "    v2, gamma2, w2, theta2, errHistory2 = NNetworkABP(dataSet, 0.1, 0.001)\n",
    "    plt.plot(np.arange(len(errHistory2)), errHistory2)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#西瓜数据集 每一列为一条数据\n",
    "features=np.array([\n",
    "    [1,2,2,1,0,1,2,2,2,1,0,0,1,0,2,0,1],\n",
    "    [2,2,2,2,2,1,1,1,1,0,0,2,1,1,1,2,2],\n",
    "    [1,0,1,0,1,1,1,1,0,2,2,1,1,0,1,1,0],\n",
    "    [0,0,0,0,0,0,1,0,1,0,2,2,1,1,0,2,1],\n",
    "    [2,2,2,2,2,1,1,1,1,0,0,0,2,2,1,0,1],\n",
    "    [1,1,1,1,1,0,0,1,1,0,1,0,1,1,0,1,1],\n",
    "    [0.697,0.774,0.634,0.608,0.556,0.403,0.481,0.437,0.666,0.243,0.245,0.343,0.639,0.657,0.360,0.593,0.719],\n",
    "    [0.460,0.376,0.264,0.318,0.215,0.237,0.149,0.211,0.091,0.267,0.057,0.099,0.161,0.198,0.370,0.042,0.103]\n",
    "])\n",
    "labels=np.array([\n",
    "    [1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0]\n",
    "])\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1./(1+np.exp(-X))\n",
    "class Net():\n",
    "    def __init__(self,num_input=8,num_hidden=10,num_output=1):\n",
    "        #隐含层和输出层的权重和偏置\n",
    "        self.W1=np.random.randn(num_hidden,num_input)\n",
    "        self.b1=np.zeros(num_hidden).reshape(-1,1)\n",
    "        self.W2=np.random.randn(num_output,num_hidden)\n",
    "        self.b2=np.zeros(num_output).reshape(-1,1)\n",
    "        #隐含层和输出层的输出\n",
    "        self.o1=np.zeros(num_hidden).reshape(-1,1)\n",
    "        self.o2=np.zeros(num_output).reshape(-1,1)\n",
    "        #梯度存储变量\n",
    "        self.do2=np.zeros(self.o2.shape)\n",
    "        self.dW2=np.zeros(self.W2.shape)\n",
    "        self.db2=np.zeros(self.b2.shape)\n",
    "        self.do1=np.zeros(self.o1.shape)\n",
    "        self.dW1=np.zeros(self.W1.shape)\n",
    "        self.db1=np.zeros(self.b1.shape)\n",
    "    def forward(self,X):#前向传播\n",
    "        if X.shape[0] != self.W1.shape[1]:\n",
    "            print(\"输入数据格式错误！\")\n",
    "            return\n",
    "        self.input=X\n",
    "        #使用sigmoid函数为激活函数\n",
    "        self.o1=sigmoid(np.matmul(self.W1,self.input)+self.b1)\n",
    "        self.o2=sigmoid(np.matmul(self.W2,self.o1)+self.b2)\n",
    "        return self.o2\n",
    "    def standard_BP(self,label,lr=0.2):#标准BP 使用均方误差为损失函数\n",
    "        #求梯度\n",
    "        self.do2=self.o2-label\n",
    "        self.dW2=np.matmul(self.do2*self.o2*(1-self.o2),self.o1.reshape(1,-1))\n",
    "        self.db2=self.do2*self.o2*(1-self.o2)\n",
    "        self.do1=np.matmul(self.W2.transpose(),self.do2*self.o2*(1-self.o2))\n",
    "        self.dW1=np.matmul(self.do1*self.o1*(1-self.o1),self.input.reshape(1,-1))\n",
    "        self.db1=self.do1*self.o1*(1-self.o1)\n",
    "        #更新参数\n",
    "        self.W2-=self.dW2*lr\n",
    "        self.b2-=self.db2*lr\n",
    "        self.W1-=self.dW1*lr\n",
    "        self.b1-=self.db1*lr\n",
    "    def accumulate_BP(self,labels,lr=0.2):#累积BP 使用均方误差为损失函数\n",
    "        num=labels.shape[1]#样本数量\n",
    "        #求梯度\n",
    "        self.do2=(self.o2-labels)/num\n",
    "        self.dW2=np.matmul(self.do2*self.o2*(1-self.o2),self.o1.transpose())\n",
    "        self.db2=(self.do2*self.o2*(1-self.o2)).sum(axis=1).reshape(-1,1)\n",
    "        self.do1=np.matmul(self.W2.transpose(),self.do2*self.o2*(1-self.o2))\n",
    "        self.dW1=np.matmul(self.do1*self.o1*(1-self.o1),self.input.transpose())\n",
    "        self.db1=(self.do1*self.o1*(1-self.o1)).sum(axis=1).reshape(-1,1)\n",
    "        #更新参数\n",
    "        self.W2-=self.dW2*lr\n",
    "        self.b2-=self.db2*lr\n",
    "        self.W1-=self.dW1*lr\n",
    "        self.b1-=self.db1*lr\n",
    "        \n",
    "def train_standard_BP(features,labels,lr):\n",
    "    net=Net()\n",
    "    epoch=0\n",
    "    loss=1\n",
    "    all_loss=[]\n",
    "    while loss>0.1:#停止条件\n",
    "        for i in range(features.shape[1]):\n",
    "            X=features[:,i]\n",
    "            Y=labels[0,i]\n",
    "            net.forward(X.reshape(-1,1))\n",
    "            net.standard_BP(Y,lr)\n",
    "        output=net.forward(features)\n",
    "        loss=0.5*((output-labels)**2).sum()\n",
    "        epoch+=1\n",
    "        all_loss.append(loss)\n",
    "    print(\"标准BP\",\"学习率：\",lr,\"\\n终止epoch：\",epoch,\"loss: \",loss)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(all_loss)\n",
    "    plt.show()\n",
    "    \n",
    "def train_accumulate_BP(features,labels,lr=0.2):\n",
    "    net=Net()\n",
    "    epoch=0\n",
    "    loss=1\n",
    "    all_loss=[]\n",
    "    while loss>0.1:#停止条件\n",
    "        output=net.forward(features)\n",
    "        net.accumulate_BP(labels,lr)\n",
    "        loss=0.5*((output-labels)**2).sum()/labels.shape[1]\n",
    "        epoch+=1\n",
    "        all_loss.append(loss)\n",
    "    print(\"累积BP\",\"学习率：\",lr,\"\\n终止epoch：\",epoch,\"loss: \",loss)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(all_loss)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = x\n",
    "z = x * y\n",
    "print(z.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
