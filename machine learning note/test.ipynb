{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集精度为: 0.9628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "class TreeNode():\n",
    "    \n",
    "    def __init__(self, model=None, C=None, left=None, right=None):\n",
    "        self.model = model\n",
    "        self.C = C\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "def trainLinear(linear, x, y):\n",
    "    #使用sklearn库的最小二乘估计训练一个线性模型\n",
    "    linear.fit(x, y)\n",
    "    return linear\n",
    "\n",
    "def binaryTrainSet(linear, x, y):\n",
    "    #根据线性回归模型二分数据集\n",
    "    #对样本x[i],其线性模型预测值若小于等于0,分到x0集合;若大于0,分到x1集合;相应的标签也划分的y0,y1集合\n",
    "    x0 = []\n",
    "    x1 = []\n",
    "    y0 = []\n",
    "    y1 = []\n",
    "    p = linear.predict(x)\n",
    "    for i in range(p.shape[0]):\n",
    "        if p[i] <= 0:\n",
    "            x0.append(x[i])\n",
    "            y0.append(y[i])\n",
    "        else:\n",
    "            x1.append(x[i])\n",
    "            y1.append(y[i])\n",
    "    return np.array(x0), np.array(x1), np.array(y0), np.array(y1)\n",
    "\n",
    "def score(linear, x, y):\n",
    "    #计算线性模型linear的精度\n",
    "    right = 0\n",
    "    p = linear.predict(x)\n",
    "    for i in range(p.shape[0]):\n",
    "        if p[i]<=0 and y[i]==-1 or p[i]>0 and y[i]==1:\n",
    "            right += 1\n",
    "    return right / x.shape[0]\n",
    "    \n",
    "def treeGenerate(root, x, y, precision):\n",
    "    #递归建造决策树\n",
    "    root.model = LinearRegression()\n",
    "    root.model = trainLinear(root.model, x, y)\n",
    "    x0, x1, y0, y1 = binaryTrainSet(root.model, x, y)\n",
    "    \n",
    "    #构建当前结点左分支\n",
    "    if len(x0)==0 or score(root.model, x0, y0)>= precision:\n",
    "        #左分支训练集为空或当前结点的线性模型对左分支的训练样本精度达到了阈值要求(precision),将左分支构建为叶子节点\n",
    "        root.left = TreeNode(C=-1)\n",
    "    else:\n",
    "        #左分支结点精度不够要求,还需进行划分\n",
    "        root.left = TreeNode()\n",
    "        treeGenerate(root.left, x0, y0, precision)\n",
    "    \n",
    "    #构建当前结点右分支\n",
    "    if len(x1)==0 or score(root.model, x1, y1) >= precision:\n",
    "        root.right = TreeNode(C=1)\n",
    "    else:\n",
    "        root.right = TreeNode()\n",
    "        treeGenerate(root.right, x1, y1, precision)\n",
    "\n",
    "def predict(root, xs):\n",
    "    #使用以root为根结点的决策树预测样本s\n",
    "    if root.C is not None:\n",
    "        #root为叶子结点\n",
    "        return root.C\n",
    "    else:\n",
    "        if root.model.predict(np.expand_dims(xs, axis=0)) <= 0:\n",
    "            return predict(root.left, xs)\n",
    "        else:\n",
    "            return predict(root.right, xs)\n",
    "\n",
    "def evaluate(root, x, y):\n",
    "    #计算以root为根结点的决策树在数据集x上的精度\n",
    "    right = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        if predict(root, x[i]) == y[i]:\n",
    "            right += 1\n",
    "    return right / x.shape[0]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #加载乳腺癌数据集\n",
    "    cancer = load_breast_cancer()\n",
    "\n",
    "    #参数random_state是指随机生成器,测试集占全部数据的33%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cancer['data'],cancer['target'], test_size=0.33, random_state=42)\n",
    "    \n",
    "    #将y_train与y_test标签中的0全部改为-1\n",
    "    y_train[y_train == 0] = -1\n",
    "    y_test[y_test == 0] = -1\n",
    "\n",
    "    #数据标准化\n",
    "    X_train = preprocessing.scale(X_train)\n",
    "    X_test = preprocessing.scale(X_test)\n",
    "    \n",
    "    #构建决策树\n",
    "    root = TreeNode()\n",
    "    #此处的阈值不能设的太大,由于数据本身就有一定客观存在的误差,无法做到100%精度,阈值设的太大容易爆栈\n",
    "    treeGenerate(root, X_train, y_train, 0.96)\n",
    "    \n",
    "    #计算训练好的决策树在测试集上的精度\n",
    "    scoreTest = evaluate(root, X_test, y_test)\n",
    "    print('测试集精度为:', round(scoreTest, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class MultivariateDecisionTree:\n",
    "    def __init__(self, max_depth=5):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # 停止条件\n",
    "        if depth == self.max_depth or n_labels == 1:\n",
    "            return np.bincount(y).argmax()\n",
    "\n",
    "        best_gain = -1\n",
    "        best_split = None\n",
    "        for _ in range(10):  # 随机尝试一些线性组合\n",
    "            weights = np.random.randn(n_features)\n",
    "            thresholds = np.linspace(np.min(np.dot(X, weights)), np.max(np.dot(X, weights)), 10)\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.dot(X, weights) < threshold\n",
    "                right_indices = ~left_indices\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "                gain = self._information_gain(y, y[left_indices], y[right_indices])\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = (weights, threshold)\n",
    "\n",
    "        if best_gain == -1:\n",
    "            return np.bincount(y).argmax()\n",
    "\n",
    "        weights, threshold = best_split\n",
    "        left_indices = np.dot(X, weights) < threshold\n",
    "        right_indices = ~left_indices\n",
    "        left_subtree = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return (weights, threshold, left_subtree, right_subtree)\n",
    "\n",
    "    def _information_gain(self, parent, left, right):\n",
    "        p = len(left) / len(parent)\n",
    "        return self._gini_impurity(parent) - p * self._gini_impurity(left) - (1 - p) * self._gini_impurity(right)\n",
    "\n",
    "    def _gini_impurity(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        impurity = 1\n",
    "        for count in counts:\n",
    "            probability = count / len(y)\n",
    "            impurity -= probability ** 2\n",
    "        return impurity\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if isinstance(node, (int, np.integer)):\n",
    "            return node\n",
    "        weights, threshold, left_subtree, right_subtree = node\n",
    "        if np.dot(x, weights) < threshold:\n",
    "            return self._traverse_tree(x, left_subtree)\n",
    "        else:\n",
    "            return self._traverse_tree(x, right_subtree)\n",
    "    \n",
    "    def print_tree(self):\n",
    "        print(self.tree)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.37911062, -0.77495183, -1.07286549,  0.01130297,  0.14936678,\n",
      "       -0.65324754,  0.7258939 ,  1.13466387, -0.02266037, -0.52108589,\n",
      "        0.25562822, -0.60208735,  0.35258349, -1.01532521,  0.2290356 ,\n",
      "        0.89588802, -0.27231618,  0.67432161,  0.58818625,  0.16331979]), 1.6275244034753538, (array([-0.50819058, -0.3447874 , -1.53204579, -0.77332478,  0.31573106,\n",
      "       -1.55046424, -2.10466126,  0.22040419,  0.4611451 ,  0.70578684,\n",
      "        0.39784242,  0.19074872, -0.50738606,  0.69407804,  1.8388488 ,\n",
      "       -1.6335679 , -0.28812144,  0.30737951,  0.91730457,  0.16929404]), -8.60940958304003, (array([-8.96482643e-01, -4.41627874e-01, -5.92344829e-01,  8.48202614e-01,\n",
      "       -1.89799724e+00, -1.92212562e-02, -9.82183406e-01, -1.06721240e+00,\n",
      "        1.07252818e-02, -1.76915798e+00,  3.42032425e+00,  7.47168782e-01,\n",
      "        7.44664302e-02, -5.59277617e-02,  1.55860235e+00,  4.94320703e-04,\n",
      "        4.93930890e-01, -1.70877543e+00, -9.51122466e-01,  8.73370291e-01]), 5.979674185697694, 1, 0), (array([ 1.06685947,  0.33529276,  1.19900852, -0.42204012, -0.62581614,\n",
      "       -0.51299347, -1.81534922, -0.83465942,  0.41319983,  0.12220583,\n",
      "        0.36627486, -0.26423452, -1.18969709, -1.53964907,  0.34780085,\n",
      "        0.628214  ,  0.21574499,  1.17025767, -0.02939858, -1.41421733]), -5.5694758595991605, (array([-0.86398669, -0.86595777,  0.23500134,  0.17811744,  1.40917919,\n",
      "       -1.27121809, -0.80294105, -0.18887869, -0.43332949,  0.80267463,\n",
      "       -0.58545731,  0.78126658,  0.85301999, -0.3560608 ,  0.29595981,\n",
      "        0.21400241,  1.18040134,  1.85808252, -0.52300578,  1.74075099]), 3.0264765357299037, (array([-1.51000234, -1.08834414,  1.0851652 ,  0.853412  ,  1.28117793,\n",
      "       -1.18910512, -0.4523648 ,  0.23468228, -0.25296841, -0.10228531,\n",
      "        1.36352716,  2.05582965, -0.13620464, -1.06309684,  0.26282192,\n",
      "        0.4331961 , -1.03079275, -0.07784775, -0.21783563,  1.34174256]), 5.810520062068381, 1, 0), (array([-1.2532358 , -0.76661105, -0.68645443, -0.57579077,  0.2779403 ,\n",
      "        0.33431373, -1.14913883,  0.88952813,  0.47011174, -0.27168074,\n",
      "        0.31898093,  0.95744091,  1.64891877, -1.00407909, -1.13330415,\n",
      "        0.53962244, -2.67712386,  0.30521389, -0.4317846 ,  1.67867742]), -4.1607844070042175, 1, 0)), (array([ 0.34431044,  1.19519605, -0.72666964,  1.84010164, -0.66949054,\n",
      "       -0.15383078,  0.90625457,  0.06346291, -0.82638101,  0.3226344 ,\n",
      "       -0.27521944,  1.63670957, -1.13544416, -0.19423357, -1.15537219,\n",
      "        0.3315634 , -0.19150402, -0.11799684, -0.35787978, -0.4508946 ]), -5.805091213806997, (array([-7.58515160e-01, -1.75133892e+00, -3.22622350e-02,  4.11239214e-01,\n",
      "       -5.07071422e-01, -4.59255056e-01, -5.50018984e-02, -3.14641882e-01,\n",
      "       -1.69138174e+00,  1.62071085e+00,  7.20016094e-01,  2.01055326e+00,\n",
      "        5.04402232e-04,  4.98565273e-01,  8.23879633e-01, -1.06312968e+00,\n",
      "       -1.41865110e-01, -2.78130570e-01, -1.00892056e+00, -1.60647677e+00]), 1.1706655448589363, 0, 1), (array([-0.56778973, -0.4475159 ,  2.1500779 ,  1.55750593, -2.03752301,\n",
      "       -1.43574232,  0.18878556,  0.28435769,  1.52945039, -0.7551572 ,\n",
      "       -1.35554095, -0.39942898, -0.43121478,  0.09771777, -1.98328064,\n",
      "       -0.60920255, -1.09835761,  0.43955089, -1.22437626, -1.45411658]), -9.788709403471689, 1, 0)))), (array([-0.45304395, -0.4872588 ,  0.16265048, -1.21535265, -1.22886992,\n",
      "        0.93067598, -0.10877514,  1.00563983, -0.25711676,  1.14320111,\n",
      "       -1.03245704, -0.63603987, -0.59525318, -1.99363972, -2.41496203,\n",
      "        0.54332704, -1.22769329,  0.22131178,  0.37514084,  0.22148253]), 4.57927235783125, (array([-1.3650949 , -1.42172533,  0.50222121,  0.74922756,  2.17608944,\n",
      "       -0.13836715, -1.18245118, -0.72462578,  0.41094415,  1.9318509 ,\n",
      "       -0.23379572,  0.54554243, -0.04374343,  0.6634557 , -0.14291791,\n",
      "        0.8340444 ,  1.11184519, -0.52714975, -0.33710566, -0.24503248]), 5.152073872288245, (array([ 0.99815131,  0.89236666, -0.37252098, -1.51879384,  0.02313517,\n",
      "        0.66181448, -0.37674984, -1.46671137,  0.4844802 ,  0.18212554,\n",
      "       -0.27925956,  0.2705348 ,  0.73752527,  0.58160129,  0.34728143,\n",
      "       -0.45438136,  0.51419291,  0.59767543, -0.44575972,  1.50325194]), 0.8357583782983689, (array([-0.02345653,  0.57954647,  0.21694999,  0.18982269,  1.91671233,\n",
      "        1.60075669, -1.04414976, -0.6040759 , -0.83090199,  1.02284207,\n",
      "        0.35699203,  0.02887297,  0.6409256 , -0.06164614,  0.36066697,\n",
      "       -0.77232038, -0.36681784, -2.30227691, -0.47382274,  1.4023328 ]), 3.028952235307438, 0, 1), (array([-0.18301701,  0.04978473, -0.48198186,  0.36690102,  1.23293031,\n",
      "       -0.87931803,  1.47466602, -0.9309708 ,  0.82425342,  0.71029589,\n",
      "       -0.35375621,  0.90299866,  1.35941641, -0.53483073, -1.66335402,\n",
      "       -0.59532751,  0.24055255,  1.14062179,  0.38517429,  2.05556496]), 7.6860958838195925, 1, 0)), (array([ 0.56652735,  1.09266961,  0.53007909,  0.57134344,  0.12664662,\n",
      "        0.67746908, -0.34813468, -0.90428925,  2.5236372 ,  1.11024165,\n",
      "       -1.21790193, -0.85325459, -0.93758749, -0.39502262,  0.28291805,\n",
      "        0.74669891, -1.89743307, -0.34256343,  1.10698174, -0.21957629]), -4.426207984880593, (array([ 0.95490113,  0.15606411,  0.86053831, -0.45873805, -0.10466348,\n",
      "       -1.96725654,  1.56616988, -0.73290735, -1.53080179,  0.12337741,\n",
      "       -0.26749684, -0.56268712,  0.29340371, -1.89227502, -0.44924999,\n",
      "       -0.15053005, -0.17170219,  0.10325197, -0.38685147, -0.84664785]), -3.800488822214533, 1, 0), (array([-0.37617441,  0.65621133,  0.51882477,  1.08896484, -1.40144469,\n",
      "        0.23835952, -0.24175698,  0.44552288,  0.71397412,  1.62096369,\n",
      "        0.29360728, -0.62028953, -0.5841281 ,  1.00328417, -0.632572  ,\n",
      "       -0.53015494, -1.18849326,  0.28607291, -0.83000189,  0.38496311]), -7.134640107107668, 0, 1))), (array([-0.66784573,  1.49593358, -0.73971579,  0.81548467,  1.18895192,\n",
      "        1.47809043, -0.88260004, -0.12492812, -1.51187409,  0.21934564,\n",
      "        0.13088138, -0.42557079,  0.53326142,  1.26361638,  0.24958662,\n",
      "        0.86916162, -0.26054678,  0.78361831,  1.32695272,  0.06166643]), 3.6330680067291414, (array([-0.11729256, -0.94149943,  1.57038792,  2.20208244, -0.89399445,\n",
      "        0.74296319, -0.13804348,  0.6685238 , -0.75399178, -0.80672338,\n",
      "       -0.83939291, -0.27204382, -1.30864402,  2.23149442,  0.50388243,\n",
      "       -0.83393886, -0.45713629,  1.84857316, -1.18637153,  1.15501754]), -2.996825697033138, (array([ 0.08606662, -1.87530515,  1.55534196, -0.80470576, -1.64695545,\n",
      "       -0.79190363, -0.59372618, -0.00674126,  0.54572024,  0.12784975,\n",
      "       -0.50667525, -0.08264398,  0.21138246, -0.92099476, -0.30634519,\n",
      "       -0.03628651, -2.05382236, -0.50618761,  1.4185922 , -1.42900535]), 9.798544641326924, 1, 0), (array([ 1.40518202,  1.04635354, -1.71230428, -1.30735496, -1.71749414,\n",
      "        1.44242819, -0.47598102, -0.41610636,  0.34548688, -0.64426927,\n",
      "       -0.07942757,  0.03405277, -0.16550029, -0.74398399,  1.43537493,\n",
      "        1.15136336, -1.80444325,  0.37949589,  0.39952137, -0.5911631 ]), 3.9283225779025024, 1, 0)), (array([-0.3612953 ,  1.32049841,  1.09825808,  0.14677815,  0.02292794,\n",
      "       -0.97468317, -0.48682615,  0.23664294, -0.88947409, -0.1685035 ,\n",
      "       -0.68665591,  0.07934379,  0.86633417, -1.4421579 ,  0.78721774,\n",
      "        0.4541217 , -0.4390366 ,  0.87520493,  1.50274985,  1.22813287]), 4.91049765620957, 0, (array([ 0.03325573,  0.25993371,  0.60716597, -0.32883182,  0.06999504,\n",
      "        1.28146085, -0.69854875, -0.38363484,  0.06332929,  0.98971247,\n",
      "        0.77720143, -1.09309323,  0.33578054, -0.34349167, -0.418535  ,\n",
      "       -1.53440079, -2.13460777,  1.01915089, -1.40153196,  0.41992716]), 0.06323707430381287, 1, 0)))))\n",
      "传统决策树的准确率: 0.5700\n",
      "多变量决策树的准确率: 0.4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n传统决策树的准确率: 0.5000\\n多变量决策树的准确率: 0.5950\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成一个具有特征交互的数据集\n",
    "def generate_complex_dataset(n_samples=1000, n_features=20):\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    # 定义更复杂的规则，涉及多个特征的非线性组合\n",
    "    y = ((X[:, 0] * X[:, 1] + X[:, 2] * X[:, 3]) * np.cos(X[:, 4]) + np.sin(X[:, 5]) * X[:, 6]) > 0\n",
    "    y = y.astype(int)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 生成数据集\n",
    "X, y = generate_complex_dataset()\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 传统决策树模型\n",
    "single_tree = DecisionTreeClassifier(random_state=42)\n",
    "single_tree.fit(X_train, y_train)\n",
    "single_tree_pred = single_tree.predict(X_test)\n",
    "single_tree_accuracy = accuracy_score(y_test, single_tree_pred)\n",
    "\n",
    "# 多变量决策树模型\n",
    "multi_tree = MultivariateDecisionTree(max_depth=5)\n",
    "multi_tree.fit(X_train, y_train)\n",
    "multi_tree_pred = multi_tree.predict(X_test)\n",
    "multi_tree_accuracy = accuracy_score(y_test, multi_tree_pred)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"传统决策树的准确率: {single_tree_accuracy:.4f}\")\n",
    "print(f\"多变量决策树的准确率: {multi_tree_accuracy:.4f}\")\n",
    "\n",
    "## 运行结果：\n",
    "'''\n",
    "传统决策树的准确率: 0.5000\n",
    "多变量决策树的准确率: 0.5950\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
